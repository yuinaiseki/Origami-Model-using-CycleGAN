{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cdd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils import ExperimentRun\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from models import build_generator, build_discriminator\n",
    "from dataset import get_dataset, get_dataset_with_mask\n",
    "import os\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191fbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_cyc, lambda_id = 10.0, 5.0\n",
    "img_size = 256\n",
    "batch_size = 4\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ea305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_generator(image_size=img_size, in_channels=4, out_channels=3)\n",
    "F = build_generator(image_size=img_size, in_channels=3, out_channels=3)\n",
    "D_X = build_discriminator(image_size=img_size)\n",
    "D_Y = build_discriminator(image_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54eeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "D_X_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "D_Y_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "L1 = lambda a, b: tf.reduce_mean(tf.abs(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb39cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 11:34:06,085 - INFO - Experiment directory: experiments\\run_20251204-113406\n"
     ]
    }
   ],
   "source": [
    "#expereiment setup\n",
    "params = {\n",
    "    \"lambda_cyc\": lambda_cyc,\n",
    "    \"lambda_id\": lambda_id,\n",
    "    \"img_size\": img_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"G_lr\": 2e-4,\n",
    "    \"n_blocks\": 9,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    **params\n",
    "}\n",
    "\n",
    "exp = ExperimentRun(params=params, config=config)\n",
    "logger = exp.get_logger()\n",
    "\n",
    "# connect checkpoint manager\n",
    "ckpt, ckpt_manager = exp.create_checkpoint_manager(\n",
    "    G=G, D_X=D_X, D_Y=D_Y,\n",
    "    G_optimizer=G_optimizer,\n",
    "    D_X_optimizer=D_X_optimizer,\n",
    "    D_Y_optimizer=D_Y_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805ca1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y, lambda_cyc, lambda_id):\n",
    "\n",
    "    # real_x: (B,H,W,4)  → RGB+mask\n",
    "    # real_y: (B,H,W,3)\n",
    "\n",
    "    real_x_rgb = real_x[..., :3]     # strip mask for losses\n",
    "    mask_x     = real_x[..., 3:]     # (B,H,W,1)\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 1. Forward translation\n",
    "        # -------------------------------------------------\n",
    "        fake_y = G(real_x, training=True)       # G: 4→3\n",
    "        fake_x = F(real_y, training=True)       # F: 3→3\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 2. Back cycle (IMPORTANT: G needs a mask)\n",
    "        # -------------------------------------------------\n",
    "        cyc_y_input = tf.concat([fake_x, mask_x], axis=-1)   # use original mask\n",
    "        cyc_y = G(cyc_y_input, training=True)                # (3ch)\n",
    "\n",
    "        cyc_x = F(fake_y, training=True)                     # (3ch)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 3. Identity loss (remove mask for F)\n",
    "        # -------------------------------------------------\n",
    "        same_y = G(tf.concat([real_y, mask_x], axis=-1), training=True)  # feed mask_x\n",
    "        same_x = F(real_x_rgb, training=True)                            # RGB only\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 4. Discriminator predictions (use RGB only)\n",
    "        # -------------------------------------------------\n",
    "        D_X_real = D_X(real_x_rgb, training=True)\n",
    "        D_X_fake = D_X(fake_x, training=True)\n",
    "\n",
    "        D_Y_real = D_Y(real_y, training=True)\n",
    "        D_Y_fake = D_Y(fake_y, training=True)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 5. GAN losses: LSGAN\n",
    "        # -------------------------------------------------\n",
    "        G_GAN_loss = mse(tf.ones_like(D_Y_fake), D_Y_fake)\n",
    "        F_GAN_loss = mse(tf.ones_like(D_X_fake), D_X_fake)\n",
    "\n",
    "        D_X_loss = 0.5 * (mse(tf.ones_like(D_X_real), D_X_real) +\n",
    "                          mse(tf.zeros_like(D_X_fake), D_X_fake))\n",
    "\n",
    "        D_Y_loss = 0.5 * (mse(tf.ones_like(D_Y_real), D_Y_real) +\n",
    "                          mse(tf.zeros_like(D_Y_fake), D_Y_fake))\n",
    "\n",
    "        \n",
    "        cycle_loss = L1(cyc_x, real_x) + L1(cyc_y, real_y)\n",
    "        id_loss = L1(same_x, real_x) + L1(same_y, real_y)\n",
    "\n",
    "        G_loss = G_GAN_loss + F_GAN_loss + lambda_cyc * cycle_loss + lambda_id * id_loss\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 9. Apply gradients\n",
    "    # -----------------------------------------------------\n",
    "    G_grads = tape.gradient(G_loss, G.trainable_variables)\n",
    "\n",
    "    D_X_grads = tape.gradient(D_X_loss, D_X.trainable_variables)\n",
    "    D_Y_grads = tape.gradient(D_Y_loss, D_Y.trainable_variables)\n",
    "\n",
    "    del tape\n",
    "\n",
    "    G_optimizer.apply_gradients(zip(G_grads, G.trainable_variables + F.trainable_variables))\n",
    "    D_X_optimizer.apply_gradients(zip(D_X_grads, D_X.trainable_variables))\n",
    "    D_Y_optimizer.apply_gradients(zip(D_Y_grads, D_Y.trainable_variables))\n",
    "\n",
    "    return (\n",
    "        G_loss, \n",
    "        D_X_loss, D_Y_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41109f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.<lambda>() missing 1 required positional argument: 'b'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainX \u001b[38;5;241m=\u001b[39m get_dataset_with_mask(\n\u001b[0;32m      2\u001b[0m     image_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/segmented/butterfly/*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     mask_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/segmented/butterfly/*_mask.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      5\u001b[0m     img_size\u001b[38;5;241m=\u001b[39mimg_size)\n\u001b[0;32m      6\u001b[0m trainY \u001b[38;5;241m=\u001b[39m get_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/origami/butterfly/*.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                      batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      8\u001b[0m                      img_size\u001b[38;5;241m=\u001b[39mimg_size)\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\Documents\\GitHub\\Origami-Model-using-CycleGAN\\CycleGAN3\\dataset.py:55\u001b[0m, in \u001b[0;36mget_dataset_with_mask\u001b[1;34m(image_pattern, mask_pattern, batch_size, img_size)\u001b[0m\n\u001b[0;32m     52\u001b[0m     msk \u001b[38;5;241m=\u001b[39m load_mask(mask_path, img_size)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconcat([img, msk], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m a, b: _load_pair(a, b), num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m     56\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(paired)))\n\u001b[0;32m     57\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2341\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_op\u001b[38;5;241m.\u001b[39m_map_v2(\n\u001b[0;32m   2342\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2343\u001b[0m     map_func,\n\u001b[0;32m   2344\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[0;32m   2345\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[0;32m   2346\u001b[0m     synchronous\u001b[38;5;241m=\u001b[39msynchronous,\n\u001b[0;32m   2347\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39muse_unbounded_threadpool,\n\u001b[0;32m   2348\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2349\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:57\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`synchronous` is not supported with `num_parallel_calls`, but\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `num_parallel_calls` was set to \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m       num_parallel_calls,\n\u001b[0;32m     56\u001b[0m   )\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     58\u001b[0m     input_dataset,\n\u001b[0;32m     59\u001b[0m     map_func,\n\u001b[0;32m     60\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[0;32m     61\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[0;32m     62\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     63\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39muse_unbounded_threadpool,\n\u001b[0;32m     64\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:202\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[0;32m    203\u001b[0m     map_func,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[0;32m    205\u001b[0m     dataset\u001b[38;5;241m=\u001b[39minput_dataset,\n\u001b[0;32m    206\u001b[0m     use_legacy_function\u001b[38;5;241m=\u001b[39muse_legacy_function)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m fn_factory()\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1256\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1255\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1257\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1226\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1224\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1225\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwargs, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1230\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[0;32m    697\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    698\u001b[0m )\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[0;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[0;32m    180\u001b[0m   )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[0;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[0;32m    285\u001b[0m )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[0;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[0;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[0;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[0;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m )\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1057\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1059\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1060\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m wrapper_helper(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, ag_ctx)(\u001b[38;5;241m*\u001b[39mnested_args)\n\u001b[0;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.<lambda>() missing 1 required positional argument: 'b'\n"
     ]
    }
   ],
   "source": [
    "trainX = get_dataset_with_mask(\n",
    "    image_pattern='data/segmented/butterfly/*.jpg',\n",
    "    mask_pattern='data/segmented/butterfly/*_mask.png',\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size)\n",
    "trainY = get_dataset('data/origami/butterfly/*.png',\n",
    "                     batch_size=batch_size,\n",
    "                     img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089aca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cardX \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcardinality(trainX)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      2\u001b[0m cardY \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcardinality(trainY)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      3\u001b[0m num_steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(cardX, cardY))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "cardX = tf.data.experimental.cardinality(trainX).numpy()\n",
    "cardY = tf.data.experimental.cardinality(trainY).numpy()\n",
    "num_steps_per_epoch = int(min(cardX, cardY))\n",
    "bar_len = 30\n",
    "ckpt_interval = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_start = time.time() \n",
    "    \n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    step = 0\n",
    "    \n",
    "    for real_x, real_y in zip(trainX, trainY):\n",
    "        step += 1\n",
    "        G_loss, DX_loss, DY_loss = train_step(real_x, real_y, lambda_cyc, lambda_id)\n",
    "        \n",
    "        bar = exp.progress_bar(step, num_steps_per_epoch, bar_len=bar_len)\n",
    "        sys.stdout.write(\n",
    "            \"\\r\"\n",
    "            f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "            f\"{bar}  step {step}/{num_steps_per_epoch}\"\n",
    "        )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # if step % 50 == 0:\n",
    "        #     logger.info(\n",
    "        #         f\"  step {step}: G={float(G_loss.numpy()):.3f} \"\n",
    "        #         f\"DX={float(DX_loss.numpy()):.3f} DY={float(DY_loss.numpy()):.3f}\"\n",
    "        #     )\n",
    "        loss_dict = {\n",
    "            \"G_loss\": G_loss,\n",
    "            \"D_X\": DX_loss,\n",
    "            \"D_Y\": DY_loss,\n",
    "        }\n",
    "        exp.log_losses(epoch + 1, step, loss_dict)\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    time_per_step = epoch_time / step\n",
    "\n",
    "    logger.info(\n",
    "        f\"Epoch {epoch+1} completed in {epoch_time:.2f}s \"\n",
    "        f\"({time_per_step:.4f}s per step)\"\n",
    "    )\n",
    "    \n",
    "    if (epoch + 1) % ckpt_interval == 0 or (epoch + 1) == num_epochs:\n",
    "        exp.save_checkpoint()\n",
    "\n",
    "    sample = next(iter(trainX))\n",
    "    fake_y = G(sample, training=False)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        logger.info(\n",
    "            \"Epoch %d: G=%.3f DX=%.3f DY=%.3f\",\n",
    "            epoch + 1, float(G_loss.numpy()), float(DX_loss.numpy()), float(DY_loss.numpy())\n",
    "        )\n",
    "        sample = next(iter(trainX))\n",
    "        fake_y = G(sample, training=False)\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1); plt.imshow((sample[0] + 1) / 2); plt.title(\"Real X\"); plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2); plt.imshow((fake_y[0] + 1) / 2); plt.title(\"Fake Y\"); plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        out_path = exp.results_dir / f\"epoch_{epoch+1}.png\"\n",
    "        plt.savefig(out_path)\n",
    "        plt.close()\n",
    "        \n",
    "print(\"\\nGenerating final comparison on test image...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = \"../../data/segmented/butterfly_0022.jpg\"\n",
    "test_mask_path = \"../../data/segmented/butterfly_0022_mask.png\"\n",
    "\n",
    "test_img = load_image(test_img_path, img_size)\n",
    "test_mask = load_mask(test_mask_path, img_size)\n",
    "\n",
    "test_input = tf.concat([test_img, test_mask], axis=-1)   # (H,W,4)\n",
    "test_input = tf.expand_dims(test_input, 0)               # (1,H,W,4)\n",
    "\n",
    "fake_y = G(test_input, training=False)                   # G: 4→3\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow((test_img + 1)/2)\n",
    "plt.title(\"Test Real X\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow((fake_y[0] + 1)/2)\n",
    "plt.title(\"Generated Origami (G(X))\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(exp.results_dir / \"final_test_example.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"✔ Saved final test output at:\", exp.results_dir / \"final_test_example.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
