{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from experiment_utils import ExperimentRun\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from models import build_generator, build_discriminator\n",
    "from dataset import get_dataset, get_dataset_with_mask\n",
    "import os\n",
    "import time, sys\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191fbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_cyc, lambda_id = 5.0, 2.5\n",
    "img_size = 256\n",
    "batch_size = 4\n",
    "num_epochs = 100\n",
    "alpha = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_generator(image_size=img_size, in_channels=4, out_channels=3)\n",
    "F = build_generator(image_size=img_size, in_channels=3, out_channels=3)\n",
    "D_X = build_discriminator(image_size=img_size)\n",
    "D_Y = build_discriminator(image_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54eeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "F_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "D_X_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "D_Y_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "L1 = lambda a, b: tf.reduce_mean(tf.abs(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG19(include_top=False, weights=\"imagenet\",\n",
    "            input_shape=(img_size, img_size, 3))\n",
    "vgg.trainable = False\n",
    "\n",
    "# Use a mid-level conv layer as perceptual features\n",
    "vgg_feature_layer = \"block3_conv3\"\n",
    "vgg_feature_extractor = tf.keras.Model(\n",
    "    inputs=vgg.input,\n",
    "    outputs=vgg.get_layer(vgg_feature_layer).output\n",
    ")\n",
    "\n",
    "def perceptual_loss(img1, img2):\n",
    "    \"\"\"\n",
    "    Perceptual L1 loss between VGG19 feature maps.\n",
    "    img1, img2 are expected in [-1, 1] range, RGB.\n",
    "    \"\"\"\n",
    "    # [-1, 1] -> [0, 255]\n",
    "    img1 = (img1 + 1.0) * 127.5\n",
    "    img2 = (img2 + 1.0) * 127.5\n",
    "\n",
    "    # VGG19 preprocessing (BGR ordering, mean subtraction, etc.)\n",
    "    img1 = preprocess_input(img1)\n",
    "    img2 = preprocess_input(img2)\n",
    "\n",
    "    # Extract feature maps\n",
    "    feat1 = vgg_feature_extractor(img1)\n",
    "    feat2 = vgg_feature_extractor(img2)\n",
    "\n",
    "    # L1 in feature space\n",
    "    return tf.reduce_mean(tf.abs(feat1 - feat2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb39cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expereiment setup\n",
    "params = {\n",
    "    \"lambda_cyc\": lambda_cyc,\n",
    "    \"lambda_id\": lambda_id,\n",
    "    \"img_size\": img_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"alpha\": alpha,\n",
    "    \"G_lr\": 1e-4,\n",
    "    \"D_lr\": 1e-4,\n",
    "    \"n_blocks\": 9,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    **params\n",
    "}\n",
    "\n",
    "exp = ExperimentRun(params=params, config=config)\n",
    "logger = exp.get_logger()\n",
    "\n",
    "# connect checkpoint manager\n",
    "ckpt, ckpt_manager = exp.create_checkpoint_manager(\n",
    "    G=G, F=F, D_X=D_X, D_Y=D_Y,\n",
    "    G_optimizer=G_optimizer,\n",
    "    F_optimizer=F_optimizer,\n",
    "    D_X_optimizer=D_X_optimizer,\n",
    "    D_Y_optimizer=D_Y_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ca1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y, lambda_cyc, lambda_id):\n",
    "\n",
    "    # real_x: (B,H,W,4)  → RGB+mask\n",
    "    # real_y: (B,H,W,3)\n",
    "\n",
    "    real_x_rgb = real_x[..., :3]     # strip mask for losses\n",
    "    mask_x     = real_x[..., 3:]     # (B,H,W,1)\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 1. Forward translation\n",
    "        # -------------------------------------------------\n",
    "        fake_y = G(real_x, training=True)       # G: 4→3\n",
    "        fake_x = F(real_y, training=True)       # F: 3→3\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 2. Back cycle (IMPORTANT: G needs a mask)\n",
    "        # -------------------------------------------------\n",
    "        cyc_y_input = tf.concat([fake_x, mask_x], axis=-1)   # use original mask\n",
    "        cyc_y = G(cyc_y_input, training=True)                # (3ch)\n",
    "\n",
    "        cyc_x = F(fake_y, training=True)                     # (3ch)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 3. Identity loss (remove mask for F)\n",
    "        # -------------------------------------------------\n",
    "        same_y = G(tf.concat([real_y, mask_x], axis=-1), training=True)  # feed mask_x\n",
    "        same_x = F(real_x_rgb, training=True)                            # RGB only\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 4. Discriminator predictions (use RGB only)\n",
    "        # -------------------------------------------------\n",
    "        D_X_real = D_X(real_x_rgb, training=True)\n",
    "        D_X_fake = D_X(fake_x, training=True)\n",
    "\n",
    "        D_Y_real = D_Y(real_y, training=True)\n",
    "        D_Y_fake = D_Y(fake_y, training=True)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 5. GAN losses: LSGAN\n",
    "        # -------------------------------------------------\n",
    "        G_GAN_loss = mse(tf.ones_like(D_Y_fake), D_Y_fake)\n",
    "        F_GAN_loss = mse(tf.ones_like(D_X_fake), D_X_fake)\n",
    "\n",
    "        D_X_loss = 0.5 * (mse(tf.ones_like(D_X_real), D_X_real) +\n",
    "                          mse(tf.zeros_like(D_X_fake), D_X_fake))\n",
    "\n",
    "        D_Y_loss = 0.5 * (mse(tf.ones_like(D_Y_real), D_Y_real) +\n",
    "                          mse(tf.zeros_like(D_Y_fake), D_Y_fake))\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 6. Cycle losses (pixel + perceptual)\n",
    "        # -------------------------------------------------\n",
    "        cycle_G_pixel = L1(cyc_y, real_y)\n",
    "        cycle_F_pixel = L1(cyc_x, real_x_rgb)\n",
    "\n",
    "        cycle_G_perc  = alpha * perceptual_loss(cyc_y, real_y)\n",
    "        cycle_F_perc  = alpha * perceptual_loss(cyc_x, real_x_rgb)\n",
    "\n",
    "        cycle_G = cycle_G_pixel + cycle_G_perc\n",
    "        cycle_F = cycle_F_pixel + cycle_F_perc\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 7. Identity loss (RGB only)\n",
    "        # -------------------------------------------------\n",
    "        id_G = L1(same_y, real_y)\n",
    "        id_F = L1(same_x, real_x_rgb)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 8. Total generator losses (separate G and F)\n",
    "        # -------------------------------------------------\n",
    "        G_loss = G_GAN_loss + lambda_cyc * cycle_G + lambda_id * id_G\n",
    "        F_loss = F_GAN_loss + lambda_cyc * cycle_F + lambda_id * id_F\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 9. Apply gradients\n",
    "    # -----------------------------------------------------\n",
    "    G_grads = tape.gradient(G_loss, G.trainable_variables)\n",
    "    F_grads = tape.gradient(F_loss, F.trainable_variables)\n",
    "\n",
    "    D_X_grads = tape.gradient(D_X_loss, D_X.trainable_variables)\n",
    "    D_Y_grads = tape.gradient(D_Y_loss, D_Y.trainable_variables)\n",
    "\n",
    "    del tape\n",
    "\n",
    "    G_optimizer.apply_gradients(zip(G_grads, G.trainable_variables))\n",
    "    F_optimizer.apply_gradients(zip(F_grads, F.trainable_variables))\n",
    "    D_X_optimizer.apply_gradients(zip(D_X_grads, D_X.trainable_variables))\n",
    "    D_Y_optimizer.apply_gradients(zip(D_Y_grads, D_Y.trainable_variables))\n",
    "\n",
    "    return (\n",
    "        G_loss, F_loss,\n",
    "        D_X_loss, D_Y_loss,\n",
    "        cycle_G_pixel, cycle_F_pixel,\n",
    "        cycle_G_perc, cycle_F_perc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41109f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX = get_dataset_with_mask(\n",
    "    image_pattern='../../data/split/segmented/trainB/butterfly/*.jpg',\n",
    "    mask_pattern='../../data/split/segmented/trainB/butterfly/*_mask.png',\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size)\n",
    "trainY = get_dataset('../../data/split/origami/train/butterfly/*.png',\n",
    "                     batch_size=batch_size,\n",
    "                     img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardX = tf.data.experimental.cardinality(trainX).numpy()\n",
    "cardY = tf.data.experimental.cardinality(trainY).numpy()\n",
    "num_steps_per_epoch = int(min(cardX, cardY))\n",
    "bar_len = 30\n",
    "ckpt_interval = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_start = time.time() \n",
    "    \n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    step = 0\n",
    "    \n",
    "    for real_x, real_y in zip(trainX, trainY):\n",
    "        step += 1\n",
    "        G_loss, F_loss, DX_loss, DY_loss, cycle_G_pixel, cycle_F_pixel, cycle_G_perc, cycle_F_perc= train_step(real_x, real_y, lambda_cyc, lambda_id)\n",
    "        \n",
    "        bar = exp.progress_bar(step, num_steps_per_epoch, bar_len=bar_len)\n",
    "        sys.stdout.write(\n",
    "            \"\\r\"\n",
    "            f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "            f\"{bar}  step {step}/{num_steps_per_epoch}\"\n",
    "        )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # if step % 50 == 0:\n",
    "        #     logger.info(\n",
    "        #         f\"  step {step}: G={float(G_loss.numpy()):.3f} \"\n",
    "        #         f\"DX={float(DX_loss.numpy()):.3f} DY={float(DY_loss.numpy()):.3f}\"\n",
    "        #     )\n",
    "        loss_dict = {\n",
    "            \"G_loss\": G_loss,\n",
    "            \"F_loss\": F_loss,\n",
    "            \"D_X\": DX_loss,\n",
    "            \"D_Y\": DY_loss,\n",
    "            \"cycle_G_pixel\": cycle_G_pixel,\n",
    "            \"cycle_F_pixel\": cycle_F_pixel,\n",
    "            \"cycle_G_perc\": cycle_G_perc,\n",
    "            \"cycle_F_perc\": cycle_F_perc,\n",
    "        }\n",
    "        exp.log_losses(epoch + 1, step, loss_dict)\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    time_per_step = epoch_time / step\n",
    "\n",
    "    logger.info(\n",
    "        f\"Epoch {epoch+1} completed in {epoch_time:.2f}s \"\n",
    "        f\"({time_per_step:.4f}s per step)\"\n",
    "    )\n",
    "    \n",
    "    if (epoch + 1) % ckpt_interval == 0 or (epoch + 1) == num_epochs:\n",
    "        exp.save_checkpoint()\n",
    "\n",
    "    sample = next(iter(trainX))\n",
    "    fake_y = G(sample, training=False)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        logger.info(\n",
    "            \"Epoch %d: G=%.3f F=%.3f DX=%.3f DY=%.3f\",\n",
    "            epoch + 1, float(G_loss.numpy()), float(F_loss.numpy()), float(DX_loss.numpy()), float(DY_loss.numpy())\n",
    "        )\n",
    "        sample = next(iter(trainX))\n",
    "        fake_y = G(sample, training=False)\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1); plt.imshow((sample[0] + 1) / 2); plt.title(\"Real X\"); plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2); plt.imshow((fake_y[0] + 1) / 2); plt.title(\"Fake Y\"); plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        out_path = exp.results_dir / f\"epoch_{epoch+1}.png\"\n",
    "        plt.savefig(out_path)\n",
    "        plt.close()\n",
    "        \n",
    "print(\"\\nGenerating final comparison on test image...\")\n",
    "\n",
    "#save model\n",
    "experiment_root = exp.results_dir.parent\n",
    "export_dir = experiment_root / \"exported\"\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "G.save(str(export_dir / \"G_full.keras\"))\n",
    "F.save(str(export_dir / \"F_full.keras\"))\n",
    "\n",
    "G.save_weights(str(export_dir / \"G_full.weights.h5\"))\n",
    "F.save_weights(str(export_dir / \"F_full.weights.h5\"))\n",
    "\n",
    "G.export(str(export_dir / \"G_savedmodel\"))\n",
    "F.export(str(export_dir / \"F_savedmodel\"))\n",
    "\n",
    "print(\"\\nSaved model artifacts:\")\n",
    "print(\"  G_full.keras\")\n",
    "print(\"  F_full.keras\")\n",
    "print(\"  G_full.weights.h5\")\n",
    "print(\"  F_full.weights.h5\")\n",
    "print(\"  G_savedmodel/\")\n",
    "print(\"  F_savedmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2794b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
