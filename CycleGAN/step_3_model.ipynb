{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93584f3a-bdf8-4754-9a8e-385d320410a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from experiment_utils import ExperimentRun\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from models import build_generator, build_discriminator\n",
    "from dataset import get_dataset\n",
    "import os\n",
    "\n",
    "# os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7a161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 0️⃣ Hyperparameters\n",
    "# ----------------------------\n",
    "lambda_cyc, lambda_id = 5.0, 2.5\n",
    "img_size = 256\n",
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "trainX_pattern = 'data/butterfly_real/*.jpeg'\n",
    "trainY_pattern = 'data/butterfly_origami/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce68bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1️⃣ Generator & Discriminator\n",
    "# ----------------------------\n",
    "G = build_generator(image_size=img_size, n_blocks=9)\n",
    "F = build_generator(image_size=img_size, n_blocks=9)\n",
    "D_X = build_discriminator(image_size=img_size)\n",
    "D_Y = build_discriminator(image_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d7278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2️⃣ Optimizer & Loss\n",
    "# ----------------------------\n",
    "G_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "D_X_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "D_Y_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "L1 = lambda a, b: tf.reduce_mean(tf.abs(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5454e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 19:31:30,419 - INFO - Experiment directory: experiments/run_20251117-193130\n"
     ]
    }
   ],
   "source": [
    "#expereiment setup\n",
    "params = {\n",
    "    \"lambda_cyc\": lambda_cyc,\n",
    "    \"lambda_id\": lambda_id,\n",
    "    \"img_size\": img_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"G_lr\": 1e-4,\n",
    "    \"D_lr\": 1e-4,\n",
    "    \"n_blocks\": 9,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    **params,\n",
    "    \"trainX_pattern\": trainX_pattern,\n",
    "    \"trainY_pattern\": trainY_pattern,\n",
    "}\n",
    "\n",
    "exp = ExperimentRun(params=params, config=config)\n",
    "logger = exp.get_logger()\n",
    "\n",
    "# connect checkpoint manager\n",
    "ckpt, ckpt_manager = exp.create_checkpoint_manager(\n",
    "    G=G, F=F, D_X=D_X, D_Y=D_Y,\n",
    "    G_optimizer=G_optimizer,\n",
    "    D_X_optimizer=D_X_optimizer,\n",
    "    D_Y_optimizer=D_Y_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd2863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3️⃣ 1 training step\n",
    "# ----------------------------\n",
    "@tf.function\n",
    "def train_step(real_x, real_y, lambda_cyc, lambda_id):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "        fake_y = G(real_x, training=True)\n",
    "        fake_x = F(real_y, training=True)\n",
    "\n",
    "        cyc_x = F(fake_y, training=True)\n",
    "        cyc_y = G(fake_x, training=True)\n",
    "\n",
    "        same_x = F(real_x, training=True)\n",
    "        same_y = G(real_y, training=True)\n",
    "\n",
    "        D_X_real = D_X(real_x, training=True)\n",
    "        D_X_fake = D_X(fake_x, training=True)\n",
    "        D_Y_real = D_Y(real_y, training=True)\n",
    "        D_Y_fake = D_Y(fake_y, training=True)\n",
    "\n",
    "        G_GAN_loss = mse(tf.ones_like(D_Y_fake), D_Y_fake)\n",
    "        F_GAN_loss = mse(tf.ones_like(D_X_fake), D_X_fake)\n",
    "\n",
    "        D_X_loss = 0.5 * (mse(tf.ones_like(D_X_real), D_X_real) + mse(tf.zeros_like(D_X_fake), D_X_fake))\n",
    "        D_Y_loss = 0.5 * (mse(tf.ones_like(D_Y_real), D_Y_real) + mse(tf.zeros_like(D_Y_fake), D_Y_fake))\n",
    "\n",
    "        cycle_loss = L1(cyc_x, real_x) + L1(cyc_y, real_y)\n",
    "        id_loss = L1(same_x, real_x) + L1(same_y, real_y)\n",
    "\n",
    "        G_total_loss = G_GAN_loss + F_GAN_loss + lambda_cyc * cycle_loss + lambda_id * id_loss\n",
    "\n",
    "    G_grads = tape.gradient(G_total_loss, G.trainable_variables + F.trainable_variables)\n",
    "    D_X_grads = tape.gradient(D_X_loss, D_X.trainable_variables)\n",
    "    D_Y_grads = tape.gradient(D_Y_loss, D_Y.trainable_variables)\n",
    "\n",
    "    del tape\n",
    "    G_optimizer.apply_gradients(zip(G_grads, G.trainable_variables + F.trainable_variables))\n",
    "    D_X_optimizer.apply_gradients(zip(D_X_grads, D_X.trainable_variables))\n",
    "    D_Y_optimizer.apply_gradients(zip(D_Y_grads, D_Y.trainable_variables))\n",
    "\n",
    "    return G_total_loss, D_X_loss, D_Y_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ Dataset\n",
    "# ----------------------------\n",
    "trainX = get_dataset('data/butterfly_real/*.jpeg', batch_size=batch_size, img_size=img_size, augment=True)\n",
    "trainY = get_dataset('data/butterfly_origami/*.jpg', batch_size=batch_size, img_size=img_size, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 5️⃣ Training cycle\n",
    "# ----------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    step = 0\n",
    "    \n",
    "    for real_x, real_y in zip(trainX, trainY):\n",
    "        step += 1\n",
    "        G_loss, DX_loss, DY_loss = train_step(real_x, real_y, lambda_cyc, lambda_id)\n",
    "        if step % 50 == 0:\n",
    "            logger.info(\n",
    "                f\"  step {step}: G={float(G_loss.numpy()):.3f} \"\n",
    "                f\"DX={float(DX_loss.numpy()):.3f} DY={float(DY_loss.numpy()):.3f}\"\n",
    "            )\n",
    "        loss_dict = {\n",
    "            \"G_total\": G_loss,\n",
    "            \"D_X\": DX_loss,\n",
    "            \"D_Y\": DY_loss,\n",
    "        }\n",
    "        exp.log_losses(epoch + 1, step, loss_dict)\n",
    "\n",
    "    exp.save_checkpoint()\n",
    "\n",
    "    sample = next(iter(trainX))\n",
    "    fake_y = G(sample, training=False)\n",
    "    exp.save_sample_image(fake_y, name=f\"epoch_{epoch+1:03d}_fake_y\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        logger.info(\n",
    "            \"Epoch %d: G=%.3f DX=%.3f DY=%.3f\",\n",
    "            epoch + 1, float(G_loss.numpy()), float(DX_loss.numpy()), float(DY_loss.numpy())\n",
    "        )\n",
    "        sample = next(iter(trainX))\n",
    "        fake_y = G(sample, training=False)\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1); plt.imshow((sample[0] + 1) / 2); plt.title(\"Real X\"); plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2); plt.imshow((fake_y[0] + 1) / 2); plt.title(\"Fake Y\"); plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        out_path = exp.results_dir / f\"epoch_{epoch+1}.png\"\n",
    "        plt.savefig(out_path)\n",
    "        plt.close()\n",
    "        \n",
    "print(\"\\nGenerating final comparison on test image...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/NST_butterfly.jpg\"\n",
    "if os.path.exists(test_path):\n",
    "    test_img = tf.io.read_file(test_path)\n",
    "    test_img = tf.image.decode_jpeg(test_img, channels=3)\n",
    "    test_img = tf.image.resize(test_img, [img_size, img_size])\n",
    "    test_img = (tf.cast(test_img, tf.float32) / 127.5) - 1.0\n",
    "    test_img = tf.expand_dims(test_img, 0)\n",
    "\n",
    "    fake_y = G(test_img, training=False)\n",
    "    fake_y = (fake_y[0] + 1.0) / 2.0\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1); plt.imshow((test_img[0] + 1) / 2.0); plt.title(\"Original Image\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2); plt.imshow(fake_y); plt.title(\"CycleGAN Output\"); plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/final_comparison.png\")\n",
    "    plt.close()\n",
    "    print(\"✅ Final comparison saved at results/final_comparison.png\")\n",
    "else:\n",
    "    print(\"⚠️ Skipped final comparison: test image not found at data/single_eval/test_img.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854c683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
