{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f40cbc4-c994-4865-8901-90941165a784",
   "metadata": {},
   "source": [
    "## Merging Data for Origami Images from 2 Datasets\n",
    "\n",
    "The following are the links to the kaggle datasets:\n",
    "\n",
    "1. https://www.kaggle.com/datasets/caokhoihuynh/orgami-works-of-some-origamists\n",
    "2. https://www.kaggle.com/datasets/karthikssalian/origami-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb2ec6-3db2-499d-9e1b-613ecf1fcfa3",
   "metadata": {},
   "source": [
    "### Dataset 1: Remove artist names and non animal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f9cfe3-3aab-4531-a8ca-73c7c71b67f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR : /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/original data/origami-artist\n",
      "WORK_DIR: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\n",
      "CLEAN_DIR: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean\n",
      "LOG_DIR : /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs\n"
     ]
    }
   ],
   "source": [
    "#Setup & Config\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "RAW_DIR   = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/original data/origami-artist\")\n",
    "WORK_DIR  = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\")\n",
    "CLEAN_DIR = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean\")\n",
    "LOG_DIR   = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs\")\n",
    "\n",
    "for p in [WORK_DIR, CLEAN_DIR, LOG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"RAW_DIR :\", RAW_DIR.resolve())\n",
    "print(\"WORK_DIR:\", WORK_DIR.resolve())\n",
    "print(\"CLEAN_DIR:\", CLEAN_DIR.resolve())\n",
    "print(\"LOG_DIR :\", LOG_DIR.resolve())\n",
    "\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\", \".tif\", \".tiff\", \".gif\"}\n",
    "\n",
    "def _is_image(p: Path) -> bool:\n",
    "    return p.is_file() and p.suffix.lower() in IMAGE_EXTS\n",
    "\n",
    "def count_images(root: Path) -> int:\n",
    "    root = Path(root)\n",
    "    n = 0\n",
    "    for base, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if Path(f).suffix.lower() in IMAGE_EXTS:\n",
    "                n += 1\n",
    "    return n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af19a129-ff9c-4b94-8d3d-23ece8ceea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image counts and folder names for tracking\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\", \".tif\", \".tiff\", \".gif\"}\n",
    "\n",
    "def _is_image(p: Path) -> bool:\n",
    "    return p.is_file() and p.suffix.lower() in IMAGE_EXTS\n",
    "\n",
    "def count_images(root: Path) -> int:\n",
    "    root = Path(root)\n",
    "    n = 0\n",
    "    for base, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if Path(f).suffix.lower() in IMAGE_EXTS:\n",
    "                n += 1\n",
    "    return n\n",
    "\n",
    "def list_all_folders(path=WORK_DIR, limit=None):\n",
    "    path = Path(path)\n",
    "    print(f\"\\nüìÅ Listing all folders in: {path.resolve()}\\n\")\n",
    "    if not path.exists():\n",
    "        print(\"‚ö†Ô∏è Path not found.\")\n",
    "        return []\n",
    "    dirs = [d for d in sorted(path.iterdir(), key=lambda x: x.name.lower()) if d.is_dir()]\n",
    "    for i, d in enumerate(dirs):\n",
    "        if limit and i >= limit:\n",
    "            print(f\"... (+{len(dirs)-limit} more)\")\n",
    "            break\n",
    "        print(f\"{i+1:3d}. {d.name}\")\n",
    "    print(f\"\\nTotal folders: {len(dirs)}\")\n",
    "    return [d.name for d in dirs]\n",
    "\n",
    "def count_images_in_each_folder(work_dir=WORK_DIR, exts=(\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".gif\",\".tiff\",\".tif\")):\n",
    "    \"\"\"\n",
    "    Returns a dict {folder_name: image_count} and prints the results.\n",
    "    \"\"\"\n",
    "    work_dir = Path(work_dir)\n",
    "    results = {}\n",
    "    total = 0\n",
    "    for folder in sorted([p for p in work_dir.iterdir() if p.is_dir()]):\n",
    "        count = 0\n",
    "        for _, _, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                if f.lower().endswith(exts):\n",
    "                    count += 1\n",
    "        results[folder.name] = count\n",
    "        total += count\n",
    "\n",
    "    width = max((len(name) for name in results), default=10)\n",
    "    print(f\"\\nüìÇ Image count per folder in {work_dir.name}:\")\n",
    "    for name, cnt in results.items():\n",
    "        print(f\"  {name.ljust(width)} : {cnt}\")\n",
    "    print(f\"\\nüñºÔ∏è Total images in WORK_DIR ({work_dir.name}): {total}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10466648-abd6-4767-a6a8-48fea36e01fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Total images in RAW_DIR (origami-artist): 3902\n"
     ]
    }
   ],
   "source": [
    "raw_image_count = count_images(RAW_DIR)\n",
    "print(f\"üñºÔ∏è Total images in RAW_DIR ({RAW_DIR.name}): {raw_image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af4762ee-fe9b-4a0a-bb21-0db07fe8c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing WORK: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\n",
      "Copying RAW ‚Üí WORK\n",
      "‚úÖ WORK ready. ~1371 dirs and 3921 files\n"
     ]
    }
   ],
   "source": [
    "#create a work data folder\n",
    "import shutil, os\n",
    "\n",
    "# Clear WORK safely\n",
    "if WORK_DIR.exists():\n",
    "    print(f\"Clearing WORK: {WORK_DIR}\")\n",
    "    shutil.rmtree(WORK_DIR)\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy tree RAW ‚Üí WORK\n",
    "print(\"Copying RAW ‚Üí WORK\")\n",
    "shutil.copytree(RAW_DIR, WORK_DIR, dirs_exist_ok=True)\n",
    "\n",
    "# Confirm\n",
    "def count_files_dirs(root: Path):\n",
    "    n_files = 0\n",
    "    n_dirs = 0\n",
    "    for base, dirs, files in os.walk(root):\n",
    "        n_files += len(files)\n",
    "        n_dirs += len(dirs)\n",
    "    return n_files, n_dirs\n",
    "\n",
    "work_files, work_dirs = count_files_dirs(WORK_DIR)\n",
    "print(f\"‚úÖ WORK ready. ~{work_dirs} dirs and {work_files} files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da3d1727-7f90-4bd5-af9c-41808a707700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artists found: 1090\n",
      "\n",
      "[ARTIST] A Rose\n",
      "  (files directly under artist: 4)\n",
      "\n",
      "[ARTIST] AcomaPot\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] AcomanPot\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Acrocinus longimanus\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Actor\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Aechmea Fasciata\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Aedes aegypti\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] African Elephant\n",
      "  (files directly under artist: 12)\n",
      "\n",
      "[ARTIST] Aged dragon\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Alamo Stallion\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Allomyrina dichotoma\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Allosaurus Skeleton\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Amaryllis\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Amatl Pot\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Ammonite\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Angel\n",
      "  (files directly under artist: 6)\n",
      "\n",
      "[ARTIST] Anna s Hummingbird Honeysuckle\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Anna s Hummingbird Trumpet Blossoms\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Anthurium\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Anzu wyliei\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Apatosaurus\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Aquarius\n",
      "  (files directly under artist: 7)\n",
      "\n",
      "[ARTIST] Archaeopteryx\n",
      "  (files directly under artist: 3)\n",
      "\n",
      "[ARTIST] Archangel Gabriel\n",
      "  (files directly under artist: 16)\n",
      "\n",
      "[ARTIST] Archangel St Michael\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Argyrops bleekeri\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Arle head\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Armadillo\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Ash Wyrm\n",
      "  (files directly under artist: 3)\n",
      "\n",
      "[ARTIST] Asian Elephant\n",
      "  (files directly under artist: 8)\n",
      "\n",
      "[ARTIST] Asian elephants\n",
      "  (files directly under artist: 3)\n",
      "\n",
      "[ARTIST] Assyrian Bull\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Asuka\n",
      "  (files directly under artist: 12)\n",
      "\n",
      "[ARTIST] Asuna\n",
      "  (files directly under artist: 4)\n",
      "\n",
      "[ARTIST] Atlas Beetle\n",
      "  (files directly under artist: 8)\n",
      "\n",
      "[ARTIST] Australia\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Ayu\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Ayu Fish\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] Azaleas\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] B Resch Tessellation\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Baby\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Balaur bondoc\n",
      "  (files directly under artist: 4)\n",
      "\n",
      "[ARTIST] Balrog\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Bambiraptor\n",
      "  (files directly under artist: 5)\n",
      "\n",
      "[ARTIST] Bambiraptor feinbergi\n",
      "  (files directly under artist: 3)\n",
      "\n",
      "[ARTIST] Banana Slug\n",
      "  (files directly under artist: 2)\n",
      "\n",
      "[ARTIST] BandPot A\n",
      "  (files directly under artist: 1)\n",
      "\n",
      "[ARTIST] Bantam\n",
      "  (files directly under artist: 14)\n",
      "\n",
      "[ARTIST] Barbarians\n",
      "  (files directly under artist: 21)\n",
      "\n",
      "[ARTIST] Baryonyx\n",
      "  (files directly under artist: 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#directory check\n",
    "from pathlib import Path\n",
    "\n",
    "def brief_tree(root: Path, max_models_per_artist=5, max_examples_per_model=3):\n",
    "    artists = [d for d in root.iterdir() if d.is_dir()]\n",
    "    print(f\"Artists found: {len(artists)}\\n\")\n",
    "    for a in sorted(artists)[:50]:\n",
    "        print(f\"[ARTIST] {a.name}\")\n",
    "        model_dirs = [d for d in a.iterdir() if d.is_dir()]\n",
    "        files = [f for f in a.iterdir() if f.is_file()]\n",
    "        if files:\n",
    "            print(f\"  (files directly under artist: {len(files)})\")\n",
    "        for m in sorted(model_dirs)[:max_models_per_artist]:\n",
    "            print(f\"  ‚îî‚îÄ [MODEL] {m.name}\")\n",
    "            imgs = [f for f in m.iterdir() if f.is_file()]\n",
    "            subdirs = [d for d in m.iterdir() if d.is_dir()]\n",
    "            if subdirs:\n",
    "                print(f\"      (nested folders under model: {len(subdirs)})\")\n",
    "            for img in imgs[:max_examples_per_model]:\n",
    "                print(f\"      ‚Ä¢ {img.name}\")\n",
    "        if len(model_dirs) > max_models_per_artist:\n",
    "            print(f\"  ... (+{len(model_dirs)-max_models_per_artist} more models)\")\n",
    "        print()\n",
    "\n",
    "if WORK_DIR.exists() and any(WORK_DIR.iterdir()):\n",
    "    brief_tree(WORK_DIR)\n",
    "else:\n",
    "    print(\"WORK_DIR is empty.\")\n",
    "\n",
    "curr_image_count = count_images(WORK_DIR)\n",
    "print(f\"üñºÔ∏è Total images in WORK_DIR ({WORK_DIR.name}): {curr_image_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c4e33c9-a812-4568-b61e-8748b07de078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping non artist directories\n",
    "from pathlib import Path\n",
    "import shutil, csv, os\n",
    "from datetime import datetime\n",
    "\n",
    "def ruleA_drop(work_dir=WORK_DIR, log_dir=LOG_DIR, dry_run=True):\n",
    "    drop_dir_names = {\"test\", \"my_model\"}\n",
    "    drop_file_names = {\"model.csv\"}\n",
    "\n",
    "    to_delete_dirs, to_delete_files = [], []\n",
    "\n",
    "    for base, dirs, files in os.walk(work_dir):\n",
    "        base_path = Path(base)\n",
    "        for d in dirs:\n",
    "            if d.lower() in drop_dir_names:\n",
    "                to_delete_dirs.append(base_path / d)\n",
    "        for f in files:\n",
    "            if f.lower() in drop_file_names:\n",
    "                to_delete_files.append(base_path / f)\n",
    "\n",
    "    # --- Logging setup ---\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    mode = \"DRY-RUN\" if dry_run else \"EXECUTE\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_path = log_dir / f\"ruleA_drop_{mode}_{timestamp}.csv\"\n",
    "\n",
    "    # --- Print summary ---\n",
    "    print(f\"\\n[{mode}]\")\n",
    "    print(f\"Found {len(to_delete_dirs)} directories and {len(to_delete_files)} files matching pattern.\\n\")\n",
    "\n",
    "    if to_delete_dirs:\n",
    "        print(\"Directories to remove (sample):\")\n",
    "        for p in to_delete_dirs[:10]:\n",
    "            print(\"  [dir]\", p)\n",
    "        if len(to_delete_dirs) > 10:\n",
    "            print(f\"  ... (+{len(to_delete_dirs)-10} more)\")\n",
    "    if to_delete_files:\n",
    "        print(\"\\nFiles to remove (sample):\")\n",
    "        for p in to_delete_files[:10]:\n",
    "            print(\"  [file]\", p)\n",
    "        if len(to_delete_files) > 10:\n",
    "            print(f\"  ... (+{len(to_delete_files)-10} more)\")\n",
    "\n",
    "    # --- Write plan to CSV ---\n",
    "    with open(log_path, \"w\", newline=\"\") as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow([\"type\", \"path\"])\n",
    "        for p in to_delete_files:\n",
    "            writer.writerow([\"file\", str(p)])\n",
    "        for p in to_delete_dirs:\n",
    "            writer.writerow([\"dir\", str(p)])\n",
    "\n",
    "    # --- Execute if not dry run ---\n",
    "    if not dry_run:\n",
    "        deleted_files = deleted_dirs = 0\n",
    "\n",
    "        # Delete files first\n",
    "        for p in to_delete_files:\n",
    "            try:\n",
    "                Path(p).unlink()\n",
    "                deleted_files += 1\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        # Delete dirs (deepest first)\n",
    "        for p in sorted(to_delete_dirs, key=lambda x: len(Path(x).parts), reverse=True):\n",
    "            try:\n",
    "                shutil.rmtree(p)\n",
    "                deleted_dirs += 1\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        print(f\"\\nDeleted {deleted_files} files and {deleted_dirs} directories.\")\n",
    "    else:\n",
    "        print(f\"\\nDry-run only. No files deleted.\")\n",
    "\n",
    "    print(f\"üßæ Log saved to: {log_path}\")\n",
    "    return to_delete_dirs, to_delete_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa54992-2095-4dd0-9c90-01fbd65da83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DRY-RUN]\n",
      "Found 2 directories and 1 files matching pattern.\n",
      "\n",
      "Directories to remove (sample):\n",
      "  [dir] /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Test\n",
      "  [dir] /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/My_model\n",
      "\n",
      "Files to remove (sample):\n",
      "  [file] /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/model.csv\n",
      "\n",
      "Dry-run only. No files deleted.\n",
      "üßæ Log saved to: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/ruleA_drop_DRY-RUN_20251013_154501.csv\n"
     ]
    }
   ],
   "source": [
    "to_del_dirs, to_del_files = ruleA_drop(dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe8a128-e5be-4265-abe2-27070e7ec198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXECUTE]\n",
      "Found 2 directories and 1 files matching pattern.\n",
      "\n",
      "Directories to remove (sample):\n",
      "  [dir] /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Test\n",
      "  [dir] /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/My_model\n",
      "\n",
      "Files to remove (sample):\n",
      "  [file] /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/model.csv\n",
      "\n",
      "Deleted 1 files and 2 directories.\n",
      "üßæ Log saved to: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/ruleA_drop_EXECUTE_20251013_154502.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([PosixPath('/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Test'),\n",
       "  PosixPath('/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/My_model')],\n",
       " [PosixPath('/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/model.csv')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruleA_drop(dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf2bded-3471-4caa-9ae2-cb7990a00087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop artist name layer\n",
    "from pathlib import Path\n",
    "import os, csv, shutil, hashlib, re\n",
    "from datetime import datetime\n",
    "\n",
    "def _sha1_short(path: Path, chunk=1024*1024) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk)\n",
    "            if not b: break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()[:10]\n",
    "\n",
    "def drop_artist(work_dir=WORK_DIR, log_dir=LOG_DIR, dry_run=True):\n",
    "    \"\"\"\n",
    "    Flatten in place:\n",
    "        work/<artist>/<model>/...  ‚Üí  work/<model>/...\n",
    "    - No normalization or fuzzy merging.\n",
    "    - If two artists share the same <model> name, they merge into the same folder.\n",
    "    - On filename collision inside a <model> folder, keep both by appending a short content hash.\n",
    "    - Removes empty artist/model folders afterwards.\n",
    "    - Writes a CSV plan/execution log to LOG_DIR.\n",
    "    \"\"\"\n",
    "    work_dir = Path(work_dir)\n",
    "    log_dir = Path(log_dir); log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Snapshot artist dirs (exclude hidden/underscore system dirs just in case)\n",
    "    artist_dirs = [d for d in work_dir.iterdir()\n",
    "                   if d.is_dir() and not d.name.startswith(\"_\")]\n",
    "\n",
    "    moves = []   # (src_file, dst_file, artist, model)\n",
    "    scanned_models = 0\n",
    "\n",
    "    # Build a stable snapshot before moving\n",
    "    for artist in sorted(artist_dirs):\n",
    "        # treat this as an \"artist\" dir only if it has subdirectories (models)\n",
    "        model_dirs = [m for m in artist.iterdir() if m.is_dir()]\n",
    "        if not model_dirs:\n",
    "            continue\n",
    "        for model in sorted(model_dirs):\n",
    "            scanned_models += 1\n",
    "            model_name = model.name  # keep as-is\n",
    "            # take all files under the model (recursively)\n",
    "            files = [p for p in model.rglob(\"*\") if p.is_file()]\n",
    "            for f in files:\n",
    "                dst_folder = work_dir / model_name\n",
    "                dst = dst_folder / f.name\n",
    "                if dst.exists():\n",
    "                    h = _sha1_short(f)\n",
    "                    dst = dst_folder / f\"{dst.stem}__{h}{dst.suffix}\"\n",
    "                moves.append((f, dst, artist.name, model_name))\n",
    "\n",
    "    mode = \"DRY-RUN\" if dry_run else \"EXECUTE\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_csv = log_dir / f\"inplace_drop_artist_{mode}_{ts}.csv\"\n",
    "\n",
    "    # Log + preview\n",
    "    with open(log_csv, \"w\", newline=\"\") as fp:\n",
    "        w = csv.writer(fp)\n",
    "        w.writerow([\"action\",\"artist\",\"model\",\"src\",\"dst\"])\n",
    "        print(f\"\\n[IN-PLACE DROP ARTIST ‚Äî {mode}]\")\n",
    "        print(f\"Scanned model folders: {scanned_models}\")\n",
    "        print(f\"Files to move        : {len(moves)}\")\n",
    "        for i, (src, dst, artist, model) in enumerate(moves[:12]):\n",
    "            print(\"  MOVE:\", src, \"‚Üí\", dst)\n",
    "            w.writerow([\"move\", artist, model, str(src), str(dst)])\n",
    "        if len(moves) > 12:\n",
    "            print(f\"  ... (+{len(moves)-12} more)\")\n",
    "            for (src, dst, artist, model) in moves[12:]:\n",
    "                w.writerow([\"move\", artist, model, str(src), str(dst)])\n",
    "\n",
    "    if dry_run:\n",
    "        print(f\"\\nüí° Dry-run only. No files moved.\")\n",
    "        print(f\"üßæ Plan saved to: {log_csv}\")\n",
    "        return {\"planned_moves\": len(moves), \"log_csv\": log_csv}\n",
    "\n",
    "    # Execute moves\n",
    "    moved = 0\n",
    "    for src, dst, artist, model in moves:\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(str(src), str(dst))\n",
    "        moved += 1\n",
    "\n",
    "    # Cleanup: remove any empty dirs left under work/\n",
    "    removed_dirs = 0\n",
    "    # Walk bottom-up so we can remove parents after children\n",
    "    for root, dirs, files in os.walk(work_dir, topdown=False):\n",
    "        # Don't try to delete the WORK root itself\n",
    "        if Path(root) == work_dir:\n",
    "            continue\n",
    "        if not dirs and not files:\n",
    "            try:\n",
    "                Path(root).rmdir()\n",
    "                removed_dirs += 1\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "    print(f\"\\nExecuted. Moved {moved} files into {work_dir}\")\n",
    "    print(f\"üßπ Removed {removed_dirs} empty directories.\")\n",
    "    print(f\"üßæ Log saved to: {log_csv}\")\n",
    "    return {\"moved_files\": moved, \"removed_dirs\": removed_dirs, \"log_csv\": log_csv}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ad98e6f-38c6-41f7-93a9-660023c92d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IN-PLACE DROP ARTIST ‚Äî DRY-RUN]\n",
      "Scanned model folders: 1337\n",
      "Files to move        : 3713\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2010/acorns.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2010/acorns.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns_2.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns_2.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns+2.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns+2.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns_3.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns_3.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns_4.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns_4.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Aerial Hunt, 2020/image.png ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Aerial Hunt, 2020/image.png\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Beaver/Beaver_1.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beaver/Beaver_1.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bee with Honeycomb, 2019/image-asset.jpeg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bee with Honeycomb, 2019/image-asset.jpeg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bird/bird_2.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bird/bird_2.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bird/bird_1.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bird/bird_1.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bird Nest, 2011/robin-nest.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bird Nest, 2011/robin-nest.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Camel, 2015/camel.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Camel, 2015/camel.jpg\n",
      "  ... (+3701 more)\n",
      "\n",
      "üí° Dry-run only. No files moved.\n",
      "üßæ Plan saved to: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/inplace_drop_artist_DRY-RUN_20251013_154518.csv\n"
     ]
    }
   ],
   "source": [
    "_ = drop_artist(dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0105aaa0-f2eb-425f-ae47-f1a08f42d5c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IN-PLACE DROP ARTIST ‚Äî EXECUTE]\n",
      "Scanned model folders: 1337\n",
      "Files to move        : 3713\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2010/acorns.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2010/acorns.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns_2.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns_2.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns+2.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns+2.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns_3.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns_3.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Acorns, 2012/Acorns_4.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Acorns, 2012/Acorns_4.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Aerial Hunt, 2020/image.png ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Aerial Hunt, 2020/image.png\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Beaver/Beaver_1.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beaver/Beaver_1.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bee with Honeycomb, 2019/image-asset.jpeg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bee with Honeycomb, 2019/image-asset.jpeg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bird/bird_2.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bird/bird_2.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bird/bird_1.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bird/bird_1.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Bird Nest, 2011/robin-nest.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Bird Nest, 2011/robin-nest.jpg\n",
      "  MOVE: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Beth Johnson/Camel, 2015/camel.jpg ‚Üí /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work/Camel, 2015/camel.jpg\n",
      "  ... (+3701 more)\n",
      "\n",
      "Executed. Moved 3713 files into /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\n",
      "üßπ Removed 1337 empty directories.\n",
      "üßæ Log saved to: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/inplace_drop_artist_EXECUTE_20251013_154521.csv\n"
     ]
    }
   ],
   "source": [
    "_ = drop_artist(dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05dc7490-ef61-41dc-805f-1cfd447315ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize folder names and merge \n",
    "from pathlib import Path\n",
    "import os, re, csv, shutil, hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _sha1_short(path: Path, chunk=1024*1024) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk)\n",
    "            if not b: break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()[:10]\n",
    "\n",
    "def _canonicalize_name(name: str) -> str:\n",
    "    # keep only alphabetic runs; lowercase; single spaces\n",
    "    runs = re.findall(r\"[A-Za-z]+\", name)\n",
    "    canon = \" \".join(r.lower() for r in runs).strip()\n",
    "    return canon or \"unnamed\"\n",
    "\n",
    "def normalize_with_staging_buckets(work_dir=WORK_DIR, log_dir=LOG_DIR, dry_run=True):\n",
    "\n",
    "    work_dir = Path(work_dir)\n",
    "    log_dir = Path(log_dir); log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    staging_root = work_dir / \"_lc_buckets\"\n",
    "\n",
    "    before_images = count_images(work_dir)\n",
    "    src_dirs = [d for d in work_dir.iterdir() if d.is_dir() and d.name != staging_root.name]\n",
    "    groups = {}\n",
    "    for d in src_dirs:\n",
    "        canon = _canonicalize_name(d.name)\n",
    "        groups.setdefault(canon, []).append(d)\n",
    "\n",
    "    mode = \"DRY-RUN\" if dry_run else \"EXECUTE\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_csv = log_dir / f\"normalize_staging_{mode}_{ts}.csv\"\n",
    "\n",
    "    planned_bucket_creates = set()\n",
    "    planned_moves = []      # (src_file, dst_file, src_dir, bucket_dir)\n",
    "    collisions = []         # (original_dst, new_dst)\n",
    "\n",
    "    # Plan: build staging buckets and move all files into them\n",
    "    for canon, dirs in sorted(groups.items(), key=lambda kv: kv[0]):\n",
    "        bucket = staging_root / canon\n",
    "        planned_bucket_creates.add(bucket)\n",
    "        for d in dirs:\n",
    "            for src in [p for p in d.rglob(\"*\") if p.is_file()]:\n",
    "                dst = bucket / src.name\n",
    "                if dst.exists():\n",
    "                    new_dst = bucket / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                    collisions.append((dst, new_dst))\n",
    "                    dst = new_dst\n",
    "                planned_moves.append((src, dst, d, bucket))\n",
    "\n",
    "    # Log & preview\n",
    "    with open(log_csv, \"w\", newline=\"\") as fp:\n",
    "        w = csv.writer(fp)\n",
    "        w.writerow([\"action\",\"src\",\"dst\",\"extra\"])\n",
    "        for b in sorted(planned_bucket_creates):\n",
    "            w.writerow([\"create_bucket\", \"\", str(b), \"\"])\n",
    "        for (orig, new) in collisions:\n",
    "            w.writerow([\"collision_rename_file\", str(orig), str(new), \"\"])\n",
    "        for src, dst, sdir, bdir in planned_moves:\n",
    "            w.writerow([\"move_to_bucket\", str(src), str(dst), f\"{sdir.name} -> {bdir.name}\"])\n",
    "\n",
    "    print(f\"\\n[NORMALIZE via STAGING ‚Äî {mode}]\")\n",
    "    print(f\"Top-level folders    : {len(src_dirs)}\")\n",
    "    print(f\"Canonical groups     : {len(groups)}\")\n",
    "    print(f\"Buckets to create    : {len(planned_bucket_creates)}\")\n",
    "    print(f\"Planned file moves   : {len(planned_moves)}\")\n",
    "    print(f\"Filename collisions  : {len(collisions)}\")\n",
    "    print(f\"üßæ Log: {log_csv}\")\n",
    "\n",
    "    # Sample preview\n",
    "    for i, b in enumerate(sorted(planned_bucket_creates)[:10]):\n",
    "        print(\"  BUCKET:\", b.name)\n",
    "    for i, (src, dst, sdir, bdir) in enumerate(planned_moves[:10]):\n",
    "        print(\"  MOVE:\", src.name, \"‚Üí\", bdir.name)\n",
    "\n",
    "    if dry_run:\n",
    "        print(f\"\\nüí° Dry-run only. No changes applied.\")\n",
    "        print(f\"üñºÔ∏è Image count (WORK_DIR): {before_images}\")\n",
    "        return {\n",
    "            \"planned_buckets\": len(planned_bucket_creates),\n",
    "            \"planned_moves\": len(planned_moves),\n",
    "            \"planned_collisions\": len(collisions),\n",
    "            \"log_csv\": log_csv,\n",
    "            \"images\": before_images\n",
    "        }\n",
    "\n",
    "    for b in sorted(planned_bucket_creates):\n",
    "        b.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    moved = 0\n",
    "    for src, dst, sdir, bdir in planned_moves:\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(str(src), str(dst))\n",
    "        moved += 1\n",
    "\n",
    "    removed_dirs = 0\n",
    "    for d in sorted(src_dirs, key=lambda p: len(p.parts), reverse=True):\n",
    "        # Skip if it is the staging root or is inside staging root\n",
    "        if d == staging_root or str(d).startswith(str(staging_root) + os.sep):\n",
    "            continue\n",
    "        # Remove empty trees bottom-up\n",
    "        for root, dirs, files in os.walk(d, topdown=False):\n",
    "            if not dirs and not files:\n",
    "                try:\n",
    "                    Path(root).rmdir()\n",
    "                    removed_dirs += 1\n",
    "                except OSError:\n",
    "                    pass\n",
    "        # Try remove the dir itself if empty\n",
    "        try:\n",
    "            d.rmdir()\n",
    "            removed_dirs += 1\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    promoted = 0\n",
    "    for b in sorted(staging_root.iterdir()):\n",
    "        if not b.is_dir():\n",
    "            continue\n",
    "        final = work_dir / b.name  # lowercase canonical name\n",
    "        if final.exists() and final != b:\n",
    "            # Should not happen (we deleted originals), but guard: merge contents\n",
    "            for src in [p for p in b.rglob(\"*\") if p.is_file()]:\n",
    "                dst = final / src.name\n",
    "                if dst.exists():\n",
    "                    dst = final / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(str(src), str(dst))\n",
    "            shutil.rmtree(b)\n",
    "            promoted += 1\n",
    "        else:\n",
    "            b.rename(final)\n",
    "            promoted += 1\n",
    "\n",
    "    try:\n",
    "        staging_root.rmdir()\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    after_images = count_images(work_dir)\n",
    "    print(f\"\\n‚úÖ Executed.\")\n",
    "    print(f\" ‚Ä¢ Files moved into buckets : {moved}\")\n",
    "    print(f\" ‚Ä¢ Original dirs removed    : {removed_dirs}\")\n",
    "    print(f\" ‚Ä¢ Buckets promoted         : {promoted}\")\n",
    "    print(f\"üñºÔ∏è Image count (WORK_DIR)  : {after_images}\")\n",
    "    print(f\"üßæ Log: {log_csv}\")\n",
    "\n",
    "    return {\n",
    "        \"moved_files\": moved,\n",
    "        \"removed_dirs\": removed_dirs,\n",
    "        \"promoted_buckets\": promoted,\n",
    "        \"log_csv\": log_csv,\n",
    "        \"images\": after_images\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1787af4a-13a1-453f-952b-3a6429b15fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NORMALIZE (letters-only, lowercase) & MERGE ‚Äî DRY-RUN]\n",
      "Folders before          : 1090\n",
      "Canonical groups        : 1090\n",
      "Dir renames (force lc)  : 0\n",
      "File moves (merges)     : 2357\n",
      "Filename collisions     : 2357\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/normalize_folders_DRY-RUN_20251013_161733.csv\n",
      "  MERGE: a_miuraken_beauty_rose_2__684326a641__684326a641__684326a641__684326a641.jpg ‚Üí a rose\n",
      "  MERGE: a_miuraken_beauty_rose_1__e9a52899ba__e9a52899ba__e9a52899ba__e9a52899ba.jpg ‚Üí a rose\n",
      "  MERGE: a_miuraken_beauty_rose_3__e04dce1168__e04dce1168__e04dce1168__e04dce1168.jpg ‚Üí a rose\n",
      "  MERGE: a_rose_1__da60985597__da60985597__da60985597__da60985597.jpg ‚Üí a rose\n",
      "  MERGE: acomanpot_1__a867b464f2__a867b464f2__a867b464f2__a867b464f2.jpg ‚Üí acomanpot\n",
      "  MERGE: acomapot_1__a956b17bba__a956b17bba__a956b17bba__a956b17bba.jpg ‚Üí acomapot\n",
      "  MERGE: acomapot_2__18f1e80b67__18f1e80b67__18f1e80b67__18f1e80b67.jpg ‚Üí acomapot\n",
      "  MERGE: acrocinus_longimanus_2__c0bb631a5e__c0bb631a5e__c0bb631a5e__c0bb631a5e.jpg ‚Üí acrocinus longimanus\n",
      "  MERGE: acrocinus_longimanus_1__f9e5119c94__f9e5119c94__f9e5119c94__f9e5119c94.jpg ‚Üí acrocinus longimanus\n",
      "  MERGE: actor_1__6b5c21eb4a__6b5c21eb4a__6b5c21eb4a__6b5c21eb4a.jpg ‚Üí actor\n",
      "\n",
      "üí° Dry-run only. No changes applied.\n",
      "üñºÔ∏è Image count (WORK_DIR): 3477\n"
     ]
    }
   ],
   "source": [
    "_ = normalize_folder_names(WORK_DIR, LOG_DIR, dry_run=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92284e08-726e-4bbe-8557-c9c707e8907c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NORMALIZE (letters-only, lowercase) & MERGE ‚Äî EXECUTE]\n",
      "Folders before          : 1090\n",
      "Canonical groups        : 1090\n",
      "Dir renames (force lc)  : 0\n",
      "File moves (merges)     : 2357\n",
      "Filename collisions     : 2357\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/normalize_folders_EXECUTE_20251013_161737.csv\n",
      "  MERGE: a_miuraken_beauty_rose_2__684326a641__684326a641__684326a641__684326a641.jpg ‚Üí a rose\n",
      "  MERGE: a_miuraken_beauty_rose_1__e9a52899ba__e9a52899ba__e9a52899ba__e9a52899ba.jpg ‚Üí a rose\n",
      "  MERGE: a_miuraken_beauty_rose_3__e04dce1168__e04dce1168__e04dce1168__e04dce1168.jpg ‚Üí a rose\n",
      "  MERGE: a_rose_1__da60985597__da60985597__da60985597__da60985597.jpg ‚Üí a rose\n",
      "  MERGE: acomanpot_1__a867b464f2__a867b464f2__a867b464f2__a867b464f2.jpg ‚Üí acomanpot\n",
      "  MERGE: acomapot_1__a956b17bba__a956b17bba__a956b17bba__a956b17bba.jpg ‚Üí acomapot\n",
      "  MERGE: acomapot_2__18f1e80b67__18f1e80b67__18f1e80b67__18f1e80b67.jpg ‚Üí acomapot\n",
      "  MERGE: acrocinus_longimanus_2__c0bb631a5e__c0bb631a5e__c0bb631a5e__c0bb631a5e.jpg ‚Üí acrocinus longimanus\n",
      "  MERGE: acrocinus_longimanus_1__f9e5119c94__f9e5119c94__f9e5119c94__f9e5119c94.jpg ‚Üí acrocinus longimanus\n",
      "  MERGE: actor_1__6b5c21eb4a__6b5c21eb4a__6b5c21eb4a__6b5c21eb4a.jpg ‚Üí actor\n",
      "\n",
      "‚úÖ Executed.\n",
      " ‚Ä¢ Renamed folders : 0\n",
      " ‚Ä¢ Merged files    : 2357\n",
      " ‚Ä¢ Removed empties : 0\n",
      " ‚Ä¢ Folders now     : 1090\n",
      "üñºÔ∏è Image count (WORK_DIR): 3477\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/normalize_folders_EXECUTE_20251013_161737.csv\n"
     ]
    }
   ],
   "source": [
    "_ = normalize_folder_names(WORK_DIR, LOG_DIR, dry_run=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e39df65-5ed6-442a-a6ab-dea1495d1e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Listing all folders in: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\n",
      "\n",
      "  1. A Rose\n",
      "  2. AcomanPot\n",
      "  3. AcomaPot\n",
      "  4. acorns\n",
      "  5. Acrocinus longimanus\n",
      "  6. Actor\n",
      "  7. Aechmea Fasciata\n",
      "  8. Aedes aegypti\n",
      "  9. aerial hunt\n",
      " 10. African Elephant\n",
      " 11. african penguin\n",
      " 12. Aged dragon\n",
      " 13. Alamo Stallion\n",
      " 14. Allomyrina dichotoma\n",
      " 15. Allosaurus Skeleton\n",
      " 16. almiraj\n",
      " 17. Amaryllis\n",
      " 18. Amatl Pot\n",
      " 19. Ammonite\n",
      " 20. ancient dragon\n",
      " 21. andira anteira taisho\n",
      " 22. Angel\n",
      " 23. ankylosaurus\n",
      " 24. Anna s Hummingbird Honeysuckle\n",
      " 25. Anna s Hummingbird Trumpet Blossoms\n",
      " 26. ant\n",
      " 27. antelope\n",
      " 28. Anthurium\n",
      " 29. Anzu wyliei\n",
      " 30. Apatosaurus\n",
      " 31. Aquarius\n",
      " 32. Archaeopteryx\n",
      " 33. Archangel Gabriel\n",
      " 34. archangel gabriel second version\n",
      " 35. archangel gabriel third version\n",
      " 36. Archangel St Michael\n",
      " 37. archeopteryx\n",
      " 38. Argyrops bleekeri\n",
      " 39. Arle head\n",
      " 40. Armadillo\n",
      " 41. Ash Wyrm\n",
      " 42. Asian Elephant\n",
      " 43. Asian elephants\n",
      " 44. asiatic elephant\n",
      " 45. Assyrian Bull\n",
      " 46. Asuka\n",
      " 47. Asuna\n",
      " 48. Atlas Beetle\n",
      " 49. Australia\n",
      " 50. Ayu\n",
      " 51. Ayu Fish\n",
      " 52. Azaleas\n",
      " 53. B Resch Tessellation\n",
      " 54. Baby\n",
      " 55. bactrian camel\n",
      " 56. Balaur bondoc\n",
      " 57. bald eagle\n",
      " 58. Balrog\n",
      " 59. Bambiraptor\n",
      " 60. Bambiraptor feinbergi\n",
      " 61. Banana Slug\n",
      " 62. BandPot A\n",
      " 63. Bantam\n",
      " 64. Barbarians\n",
      " 65. barn owl\n",
      " 66. Baryonyx\n",
      " 67. Baryonyx walkeri\n",
      " 68. basiliscus\n",
      " 69. basilisk\n",
      " 70. Basset Hound\n",
      " 71. Bassist\n",
      " 72. Bat\n",
      " 73. Bear\n",
      " 74. Bear Cub\n",
      " 75. Beaver\n",
      " 76. bee with honeycomb\n",
      " 77. beetle vs stag beetle\n",
      " 78. betamon\n",
      " 79. Beth Johnson\n",
      " 80. Betta\n",
      " 81. BiCurvePot\n",
      " 82. BicurvePotB\n",
      " 83. Bird\n",
      " 84. Bird in the Hand\n",
      " 85. bird nest\n",
      " 86. bird of frey\n",
      " 87. Birdwing Butterfly\n",
      " 88. Birth\n",
      " 89. bison\n",
      " 90. Black Forest Cuckoo Clock\n",
      " 91. black heron hunt\n",
      " 92. black heron walk\n",
      " 93. black kite\n",
      " 94. black panther\n",
      " 95. Black Pine Sawyer\n",
      " 96. Black Widow\n",
      " 97. Blackdevil Angler\n",
      " 98. blakistons fish owl\n",
      " 99. Blue Crab\n",
      "100. blue dream dancer\n",
      "101. Blue Heron\n",
      "102. Bluespine unicornfish\n",
      "103. Boar\n",
      "104. boars\n",
      "105. Boeing Icosahedral\n",
      "106. Bose\n",
      "107. Brachiosaurus\n",
      "108. Brown Widow HP\n",
      "109. Buddha\n",
      "110. Budgie\n",
      "111. Budgies\n",
      "112. buffalo\n",
      "113. bug\n",
      "114. bug on a flower\n",
      "115. Buh\n",
      "116. Buitreraptor\n",
      "117. Buitreraptor gonzalezorum\n",
      "118. bukan and tiger\n",
      "119. Bull\n",
      "120. Bull Moose\n",
      "121. Bulldozer\n",
      "122. Bunny Girl\n",
      "123. Burr Puzzle\n",
      "124. Busts\n",
      "125. butterfly\n",
      "126. byg zam\n",
      "127. Cactus\n",
      "128. Camel\n",
      "129. camel cricket v\n",
      "130. Camel Spider\n",
      "131. CamphorPot\n",
      "132. Capricorn\n",
      "133. Caravan\n",
      "134. Cardinal\n",
      "135. cardinal for davey\n",
      "136. cardinal in flight\n",
      "137. caribou\n",
      "138. Carnotaurus\n",
      "139. Carp\n",
      "140. Cat\n",
      "141. caterpillar\n",
      "142. caterpiller\n",
      "143. cattle\n",
      "144. Cattleya\n",
      "145. catura shotora taisho\n",
      "146. Caucasian Beetle\n",
      "147. Caucasus beetle\n",
      "148. cavalier\n",
      "149. Cave King\n",
      "150. Centaur\n",
      "151. Centipede\n",
      "152. cerberus\n",
      "153. Chameleon Dragonfly\n",
      "154. Chamois\n",
      "155. CHAR ZAKU\n",
      "156. charaznable helmet\n",
      "157. charley harper cardinal\n",
      "158. charlie chaplin\n",
      "159. Chen Xiao\n",
      "160. Cherubim\n",
      "161. chibi t rex\n",
      "162. Chick\n",
      "163. chicken\n",
      "164. chimera\n",
      "165. chinese yang long armed beetle\n",
      "166. Chipmunk\n",
      "167. Chirikuwagata\n",
      "168. chocobo\n",
      "169. Choi Ju Young\n",
      "170. Chow chow\n",
      "171. christmas kabuto\n",
      "172. Chrysina Beetle\n",
      "173. Chum salmon\n",
      "174. cicada\n",
      "175. cicada nymph\n",
      "176. Cicada Nymph Ia\n",
      "177. cicada v\n",
      "178. Classical Cicada\n",
      "179. Classical Cicada and Nymph\n",
      "180. Clay doll of lifter\n",
      "181. Cliff Swallow\n",
      "182. Clione\n",
      "183. Clown mask\n",
      "184. cockroach\n",
      "185. Coconut crab\n",
      "186. coelophysis\n",
      "187. Coelophysis bauri\n",
      "188. coffee dragon\n",
      "189. ColleenPot\n",
      "190. Collie\n",
      "191. Colombine with rose\n",
      "192. Columbine\n",
      "193. Commedia DellArte\n",
      "194. Cone ThreeWay\n",
      "195. Cooper s Hawk\n",
      "196. copper mesh face\n",
      "197. Copper Pheasant\n",
      "198. Cow\n",
      "199. crab\n",
      "200. crane\n",
      "201. Crested serpent eagle\n",
      "202. Cretaceous sea\n",
      "203. crocodile\n",
      "204. Crow\n",
      "205. Crows\n",
      "206. Cruel Mules\n",
      "207. Crying Ogre\n",
      "208. Cryolophosaurus\n",
      "209. Cube Snail\n",
      "210. Curved Square Weave\n",
      "211. Cyclomatus metallifer\n",
      "212. Cyclommatus metalifer\n",
      "213. cyclommatus metallifer\n",
      "214. Cyon\n",
      "215. cyriopalus\n",
      "216. D Wall\n",
      "217. Daffodollar\n",
      "218. Daji\n",
      "219. dance with the wind\n",
      "220. Dancers\n",
      "221. Dancing Crane\n",
      "222. Darwin s Orchid\n",
      "223. darwins beetle\n",
      "224. Davidic Resch\n",
      "225. Deathwing\n",
      "226. deer\n",
      "227. degree snail\n",
      "228. deinonychus\n",
      "229. dendrobium\n",
      "230. Denim MMMV Pillars\n",
      "231. Denim PCOC Pot\n",
      "232. Denim Tarantula\n",
      "233. Denim Turtle\n",
      "234. Desert evening primrose\n",
      "235. Desert locust\n",
      "236. Desert Tortoise\n",
      "237. diamond\n",
      "238. Dilong paradoxus\n",
      "239. Dimetrodon\n",
      "240. Dinnerware\n",
      "241. Dino\n",
      "242. Diplodocus\n",
      "243. Doe\n",
      "244. Dog\n",
      "245. Dogwood Blossom\n",
      "246. Dollar book\n",
      "247. Dollar buildings\n",
      "248. Dollar Butterfly\n",
      "249. Dollar Camera\n",
      "250. Dollar F Joint Strike Fighter\n",
      "251. Dollar Flipflops\n",
      "252. Dollar Goblet\n",
      "253. Dollar Shirt and Tie\n",
      "254. Dollar Surfer with Breaking Wave\n",
      "255. Dollar Surfer with Wave\n",
      "256. Dollar Tropical Scene\n",
      "257. dolphin\n",
      "258. Donquixote\n",
      "259. Dorcus hopei binodulosus\n",
      "260. Dorcus titanus\n",
      "261. Dove\n",
      "262. Dragon\n",
      "263. dragon drive\n",
      "264. Dragon Drop\n",
      "265. Dragon Knight\n",
      "266. Dragonfly\n",
      "267. Dragonfly for Dinh\n",
      "268. Dragonfly TPS\n",
      "269. Dragonfly varileg\n",
      "270. Dragonoid\n",
      "271. drake\n",
      "272. dream dancer\n",
      "273. dreamer\n",
      "274. dreaming cat\n",
      "275. Dressed Rabbit\n",
      "276. Dromaeosaurus\n",
      "277. Dromaeosaurus albertensis\n",
      "278. Drott\n",
      "279. Drupa Horse\n",
      "280. Dryad\n",
      "281. duck\n",
      "282. Eagle\n",
      "283. Eastern Dragon\n",
      "284. Egg Tessellation\n",
      "285. Elephant\n",
      "286. Elephant Beetle\n",
      "287. Elephant to Elephant\n",
      "288. Elevated Icosahedron\n",
      "289. elk\n",
      "290. Embedded Dodecahedron\n",
      "291. Emperor Scorpion\n",
      "292. Emu\n",
      "293. Encyclia\n",
      "294. Ent\n",
      "295. Epidendrosaurus\n",
      "296. Epidendrosaurus ningchengensis\n",
      "297. Epidexipteryx hui\n",
      "298. erabu black banded sea krait\n",
      "299. Eric Joisel\n",
      "300. Ethmostigmus\n",
      "301. Eupatorus gracilicornis\n",
      "302. eurypterus\n",
      "303. Eurypterus remipes\n",
      "304. Euthysanius Beetle II\n",
      "305. Evangelion\n",
      "306. Excavator\n",
      "307. Fairy\n",
      "308. Fairy Doll\n",
      "309. Fan Warp\n",
      "310. fat cardinals\n",
      "311. FatPot\n",
      "312. fennec fox\n",
      "313. Fiddler Crab\n",
      "314. Fiddler crabs\n",
      "315. Field mouse\n",
      "316. fighting bull\n",
      "317. Finch\n",
      "318. Firefly\n",
      "319. Firing Dragon\n",
      "320. Fish\n",
      "321. fish with waves\n",
      "322. FiveFold TwoLayer Weave\n",
      "323. Flame snapper\n",
      "324. Flapjack Octopus\n",
      "325. flapping long tailed tit\n",
      "326. Flight\n",
      "327. Flight of Folds contemporary\n",
      "328. Flight of Folds maquette on granite\n",
      "329. Flight of Folds maquette on stone\n",
      "330. Flight of Folds monument\n",
      "331. Flight of Folds on stone\n",
      "332. flowing nude\n",
      "333. Flugelschenk\n",
      "334. Flying Cicada\n",
      "335. Flying Crane\n",
      "336. Flying dragon\n",
      "337. Flying Eupatorus gracilicornis\n",
      "338. flying fish\n",
      "339. Flying Giant Stag Beetle\n",
      "340. Flying grasshopper\n",
      "341. Flying Great Horned Owl\n",
      "342. Flying Katydid\n",
      "343. Flying Ladybird Beetle\n",
      "344. Flying mantis\n",
      "345. Flying Peace\n",
      "346. Flying Peace maquette\n",
      "347. Flying Peace mini\n",
      "348. Flying Peace monument\n",
      "349. flying pig\n",
      "350. Flying Squirrel\n",
      "351. Flying Walking Stick\n",
      "352. Folded Friends\n",
      "353. forest scorpion v\n",
      "354. Fox\n",
      "355. Fox cub\n",
      "356. fox groom\n",
      "357. Fox in hunt\n",
      "358. fox wedding procession\n",
      "359. fox wedding retainers\n",
      "360. foxcub\n",
      "361. Frandre Scarlet\n",
      "362. Freshwater Crab\n",
      "363. Freshwater Prawn\n",
      "364. frilled neck lizard\n",
      "365. frog\n",
      "366. furina s seafood friends\n",
      "367. Galapagos Tortoise\n",
      "368. Gandalf\n",
      "369. Ganyu\n",
      "370. Garden Spider L\n",
      "371. Garden Spider LPS\n",
      "372. Garibaldi\n",
      "373. garuda\n",
      "374. Gasherbrum\n",
      "375. Geistk mpfer\n",
      "376. Gen Hagiwara\n",
      "377. Gerbil\n",
      "378. Ghost Deer\n",
      "379. Giang Dinh\n",
      "380. Giant ant eater\n",
      "381. Giant anteater\n",
      "382. Giant mottled eel\n",
      "383. Giant trevally\n",
      "384. Giant water bug\n",
      "385. Giganotosaurus\n",
      "386. giraffe\n",
      "387. Girl\n",
      "388. girl and cat\n",
      "389. girls bp\n",
      "390. Glacial prosauropod\n",
      "391. Gnome\n",
      "392. Goatfish\n",
      "393. Goby\n",
      "394. God of Thunder\n",
      "395. Goddness of moon\n",
      "396. godzilla\n",
      "397. Golden Eagle\n",
      "398. golden ringed dragonfly\n",
      "399. Golden Rooster\n",
      "400. Goldfish\n",
      "401. Goliath Beetle\n",
      "402. Gorilla\n",
      "403. GrailPot\n",
      "404. Grasshopper\n",
      "405. Gray Whale\n",
      "406. great cormorant\n",
      "407. Great scarab beetle\n",
      "408. great white shark\n",
      "409. Greater Kudu\n",
      "410. GreenCrowned Brilliant\n",
      "411. grey faced buzzard\n",
      "412. Grey Shark\n",
      "413. Greyhound\n",
      "414. griffin\n",
      "415. Grim reaper\n",
      "416. Grizzly Bear\n",
      "417. GT\n",
      "418. Guanlong wucaii\n",
      "419. Guinea Pig\n",
      "420. Guitarist\n",
      "421. Guyver Unit I\n",
      "422. Hachiko\n",
      "423. Hachiko II\n",
      "424. hamster\n",
      "425. handstand animals\n",
      "426. Hatching Sea Turtle\n",
      "427. Haverhill Fritillary\n",
      "428. Hawk eyes\n",
      "429. headfirst\n",
      "430. heart snail\n",
      "431. Hedgedog\n",
      "432. hedgehog\n",
      "433. hercules beetle\n",
      "434. hermit crab\n",
      "435. Hero s Horse maquette\n",
      "436. Hero s Horse monument\n",
      "437. hex owl\n",
      "438. Hexabox\n",
      "439. Hexagram Condensed\n",
      "440. Hexagram Tessellation\n",
      "441. Hexonion\n",
      "442. Hideko s Goldfish\n",
      "443. Hideo Komatsu\n",
      "444. hippo\n",
      "445. Hippocumpus\n",
      "446. hippopotamus\n",
      "447. Hojyo Takashi\n",
      "448. Hollow Rose\n",
      "449. homage to the bird base\n",
      "450. home bears\n",
      "451. Honeycomb\n",
      "452. horned crane\n",
      "453. horned owl\n",
      "454. Horse\n",
      "455. Horse head\n",
      "456. Horsefly\n",
      "457. Horseshoe Crab\n",
      "458. Houndfish\n",
      "459. House with Open Door\n",
      "460. Houstonia pussila\n",
      "461. Hummingbird Trumpet Vine\n",
      "462. Humpback whale\n",
      "463. Humphead wrasse\n",
      "464. Hutao\n",
      "465. hy gogg\n",
      "466. Hyperbolic Limit\n",
      "467. Hypseleotris cyprinoides\n",
      "468. I want to fly\n",
      "469. Ibex\n",
      "470. Icarus\n",
      "471. Ichthyovenator laosensis\n",
      "472. IJ Fedora\n",
      "473. inari\n",
      "474. Indian\n",
      "475. indominus rex\n",
      "476. Indy Heron\n",
      "477. infinity kiss\n",
      "478. Inimicus japonicus\n",
      "479. Inside Out\n",
      "480. Invicta\n",
      "481. irish elk\n",
      "482. ishihara fox\n",
      "483. Isisaurus colberti\n",
      "484. jack o lantern\n",
      "485. Jack Russell Terrier\n",
      "486. jackalope\n",
      "487. Jackson s Chameleon\n",
      "488. Jackson s Chameleon and Butterfly\n",
      "489. japanese bantam\n",
      "490. Japanese fluvial sculpin\n",
      "491. Japanese giant salamander\n",
      "492. Japanese huchen\n",
      "493. Japanese katydid\n",
      "494. Japanese Macaque\n",
      "495. Japanese rhinoceros beetle\n",
      "496. Japanese rockfish\n",
      "497. Japanese sea bass\n",
      "498. japanese serow\n",
      "499. japanese spiny lobster\n",
      "500. japanese toad\n",
      "501. japanese tree frog\n",
      "502. japanese white eye\n",
      "503. java sparrow\n",
      "504. jeanne d arc\n",
      "505. Jellyfish\n",
      "506. Jerboa\n",
      "507. John dory\n",
      "508. Jojolion\n",
      "509. joyride\n",
      "510. julius pringles\n",
      "511. Jumping spider\n",
      "512. K\n",
      "513. Kabutomushi\n",
      "514. kabutomushi v\n",
      "515. Kaede Nakamura\n",
      "516. Kamisato Ayaka\n",
      "517. Kamiya Satoshi\n",
      "518. Kangaroo\n",
      "519. Kannon\n",
      "520. Kanyamatoiwarebiko no Sumeramikoto\n",
      "521. Karaku Tengu\n",
      "522. Katou Megumi\n",
      "523. Katsuta Kyohei\n",
      "524. Katydid HP\n",
      "525. Kei Watanabe\n",
      "526. Kendo\n",
      "527. Kendo Swordman\n",
      "528. kentrosaurus\n",
      "529. Kingfisher\n",
      "530. Kirin\n",
      "531. kirin qirin\n",
      "532. Kitten\n",
      "533. Kiwi\n",
      "534. Klee\n",
      "535. Klein Bottle\n",
      "536. Knight Jaw\n",
      "537. KNL Dragon\n",
      "538. Koala\n",
      "539. Koi\n",
      "540. koinobori carp streamer\n",
      "541. Kokushibo\n",
      "542. korean warrior\n",
      "543. Kota Imai\n",
      "544. kuchinoshima ushi\n",
      "545. Kudu\n",
      "546. Kuhlia rupestris\n",
      "547. Kurumi\n",
      "548. kzinssie type\n",
      "549. Labrador Retriever\n",
      "550. Lakshmi\n",
      "551. lama\n",
      "552. Lan Ling Gagaku\n",
      "553. Largehead hairtail\n",
      "554. Largemouth bass\n",
      "555. Larva Wyrm\n",
      "556. Lavalamp\n",
      "557. Lazy\n",
      "558. lazy cat\n",
      "559. Lazy Rabbit\n",
      "560. Lazy seal\n",
      "561. leaf insect v\n",
      "562. leafy sea dragon\n",
      "563. leopard\n",
      "564. light wind\n",
      "565. Lion\n",
      "566. lion bwe\n",
      "567. lion man\n",
      "568. Lionfish\n",
      "569. Little bird\n",
      "570. Little dragonfish\n",
      "571. Lizard\n",
      "572. Locust\n",
      "573. locust v\n",
      "574. long tailed tit\n",
      "575. longheaded locust\n",
      "576. Longhorn Beetle\n",
      "577. Longhorn Skull\n",
      "578. Longnecked Seed Bug\n",
      "579. Longtooth grouper\n",
      "580. Lotus Temple\n",
      "581. Louvre Pyramid\n",
      "582. lovers\n",
      "583. lucanus\n",
      "584. lucanus cervus judaicus v\n",
      "585. lucanus maculifemoratus\n",
      "586. Lucanus stag beetle\n",
      "587. Lucifer\n",
      "588. luna moth\n",
      "589. Lying\n",
      "590. Lynette\n",
      "591. lyrebird\n",
      "592. Magition\n",
      "593. mahoraga makora taisho\n",
      "594. MAI\n",
      "595. Maid\n",
      "596. Maine Lobster\n",
      "597. Maitreya\n",
      "598. Makalu\n",
      "599. Makima\n",
      "600. malayan tapir\n",
      "601. mama and baby\n",
      "602. mame inari\n",
      "603. Mamenchisaurus sinocanadorum\n",
      "604. Mameshiba\n",
      "605. Mammoth\n",
      "606. Mammuthus\n",
      "607. mammuthus primigenius\n",
      "608. Man\n",
      "609. Mandibular Molar\n",
      "610. Mangrove red snapper\n",
      "611. manta\n",
      "612. Mantis shrimp\n",
      "613. Mary Anne s Butterfly\n",
      "614. Mash Kyrielight\n",
      "615. Masiakasaurus knopfleri\n",
      "616. Mask\n",
      "617. Matrona basilaris japonica\n",
      "618. Megaraptor namunhuaiquii\n",
      "619. megasoma\n",
      "620. Melanorosaurus thabanensis\n",
      "621. Meltryllis\n",
      "622. melusine fgo\n",
      "623. merlion\n",
      "624. Mermaid\n",
      "625. mewarawa\n",
      "626. mice\n",
      "627. Microraptor gui\n",
      "628. Migrating Peace maquette\n",
      "629. Miku\n",
      "630. Minamimachi Butterfly\n",
      "631. minotaur\n",
      "632. mixopterus\n",
      "633. Miyama Stag Beetle\n",
      "634. MMMV Pillars\n",
      "635. modular chicken\n",
      "636. Modular Khumbhira and Base of modular Twelve Heavenly Generals\n",
      "637. Modular Robot with Eyebrows\n",
      "638. Modular SF figures\n",
      "639. Modular violinist\n",
      "640. mole cricket\n",
      "641. Molecular Tessellation\n",
      "642. Monkey\n",
      "643. Monkfish\n",
      "644. Morgan\n",
      "645. Morning glory\n",
      "646. Mosasaurus\n",
      "647. mother and child\n",
      "648. Mountain Fox\n",
      "649. Mountain Lion\n",
      "650. Mouse\n",
      "651. Mt Diablo Tarantula\n",
      "652. mt fuji\n",
      "653. Mu Shu\n",
      "654. Mule Deer\n",
      "655. Murex\n",
      "656. mushroom\n",
      "657. Musicians\n",
      "658. Musk shrew\n",
      "659. muskox\n",
      "660. MWV\n",
      "661. n hump camel\n",
      "662. Nasobema\n",
      "663. Nautlius Shell\n",
      "664. Nazgul\n",
      "665. Neocogniauxia\n",
      "666. Neocogniauxia monophylla\n",
      "667. Neolucanus okinawanus\n",
      "668. Neptunus beetle\n",
      "669. Niem\n",
      "670. Night Hunter\n",
      "671. nine tailed fox\n",
      "672. NineDollar Lobster\n",
      "673. Northern Mockingbird\n",
      "674. Nothronychus\n",
      "675. nude back\n",
      "676. Nyoirin Kannon\n",
      "677. Oar fish\n",
      "678. Octagram Tessellation\n",
      "679. Octet Truss\n",
      "680. octopus\n",
      "681. Ohmu\n",
      "682. Okina\n",
      "683. okinawa black breasted leaf turtle\n",
      "684. okinawa rail\n",
      "685. Okinawa rails\n",
      "686. Okinawa woodpecker\n",
      "687. Omala Stallion\n",
      "688. One in a Billion silver\n",
      "689. One in a Billion white\n",
      "690. opah\n",
      "691. Open Rattan Weave\n",
      "692. Ophieleotris\n",
      "693. Opsariichthys platypus\n",
      "694. Opsariichthys uncirostris\n",
      "695. Orange fish\n",
      "696. Orangutan\n",
      "697. Orb Weaver\n",
      "698. Orchestra\n",
      "699. Orchid\n",
      "700. Orchid HB\n",
      "701. Organist\n",
      "702. Origamido Koi\n",
      "703. Ornithomimus velox\n",
      "704. Osprey\n",
      "705. Ostrich\n",
      "706. otocinclus\n",
      "707. OtomiPot\n",
      "708. Otter\n",
      "709. Oval Tessellation\n",
      "710. Owl\n",
      "711. owl for tomoko\n",
      "712. Ox\n",
      "713. Pacific bluefin tuna\n",
      "714. Pacific saury\n",
      "715. Pajarita Cube\n",
      "716. Pajarita Puzzle Cube\n",
      "717. pajra haira taisho\n",
      "718. Pale bleak\n",
      "719. panda\n",
      "720. Pangolin\n",
      "721. paper spirits\n",
      "722. Paper Wasp\n",
      "723. papillon\n",
      "724. paraceratherium\n",
      "725. Parakeet\n",
      "726. Parakeet variations\n",
      "727. Parasaurolophus\n",
      "728. Parasaurolophus walkeri\n",
      "729. paratrachelophorus longicornis\n",
      "730. patamon\n",
      "731. paw pad\n",
      "732. PCOC Pot\n",
      "733. Pea Pod\n",
      "734. Peace Flight\n",
      "735. Peach blossoms\n",
      "736. Peacock spider\n",
      "737. Pegasus\n",
      "738. Pegasus mini\n",
      "739. Pelican\n",
      "740. Penguin\n",
      "741. penguin chick\n",
      "742. pennant coralfish\n",
      "743. Pentasia\n",
      "744. Perching Cardinal\n",
      "745. Peregrine Falcon\n",
      "746. Periodical Cicada\n",
      "747. persian cat\n",
      "748. persian cat head\n",
      "749. Peter s Snowflake\n",
      "750. Phalaenopsis\n",
      "751. pheasant\n",
      "752. phoenix\n",
      "753. Pieta\n",
      "754. Pig\n",
      "755. Pill Bug\n",
      "756. Pine Bark Beetle\n",
      "757. pinecones\n",
      "758. Plague doctor s mask\n",
      "759. Platypus\n",
      "760. Playing cat\n",
      "761. Plumpy dragon\n",
      "762. Podothecus sachi\n",
      "763. Poison Dart Frog HP\n",
      "764. Polar\n",
      "765. pomeranian\n",
      "766. pony\n",
      "767. Poppy\n",
      "768. Porsche\n",
      "769. Post Generic Beetle\n",
      "770. Pouncy Cat\n",
      "771. prawn\n",
      "772. prayer\n",
      "773. prayforaustralia\n",
      "774. praying mantis\n",
      "775. praying mantis v\n",
      "776. Prosopocoilus inclinatus\n",
      "777. prosopocoilus inclinatus v\n",
      "778. pseudoscorpion\n",
      "779. pteranodon\n",
      "780. Pterosaur skeleton\n",
      "781. puffin\n",
      "782. pureland wizard\n",
      "783. Purple Art\n",
      "784. Python\n",
      "785. Quail skeletal\n",
      "786. Quetzalcoatlus\n",
      "787. Quetzalcoatrus\n",
      "788. QuezadaMoselyPot\n",
      "789. QuezadanPot\n",
      "790. QuezadaPot\n",
      "791. r dorothy\n",
      "792. Rabbit\n",
      "793. raccoon\n",
      "794. raccoon dog\n",
      "795. rafflesia\n",
      "796. Raiden shogun\n",
      "797. Raptor\n",
      "798. Rastrelliger kanagurta\n",
      "799. Rat\n",
      "800. Rattlesnake\n",
      "801. Raven\n",
      "802. ray\n",
      "803. red fox\n",
      "804. Red frog crab\n",
      "805. Red Gurnard\n",
      "806. red jungle fowl\n",
      "807. Red knight\n",
      "808. Red lionfish\n",
      "809. red panda\n",
      "810. Red sea bream\n",
      "811. Red seabream\n",
      "812. Redeared Slider\n",
      "813. Redpath Pteranodon\n",
      "814. RedTailed Hawk\n",
      "815. RedWinged Blackbird\n",
      "816. Reindeer\n",
      "817. Resting flying fox\n",
      "818. Rhinoceros\n",
      "819. Rhinoceros beetle\n",
      "820. RimPot\n",
      "821. Rings\n",
      "822. RingsFlower\n",
      "823. River Otter\n",
      "824. Robert J Lang\n",
      "825. Rock\n",
      "826. Rock Climber\n",
      "827. Rofubola Unicorn\n",
      "828. Roosevelt Elk\n",
      "829. Rooster\n",
      "830. Roses and Lilies\n",
      "831. Roses and Thorns\n",
      "832. Rosy Finch\n",
      "833. Rubythroated Hummingbird\n",
      "834. Ruddy Kingfisher\n",
      "835. Ryu\n",
      "836. ryujin\n",
      "837. Ryukyu grounded gecko\n",
      "838. s boar\n",
      "839. s pig\n",
      "840. s rooster\n",
      "841. Saber Alter\n",
      "842. Salangidae\n",
      "843. Salmon\n",
      "844. Salt Creek Tiger Beetle\n",
      "845. Samurai\n",
      "846. samurai helmet beetle\n",
      "847. Sand Dollar\n",
      "848. sandilya santeira taisho\n",
      "849. santa\n",
      "850. Santa Claus\n",
      "851. santa ornament\n",
      "852. Sarcosuchus skeleton\n",
      "853. Sauronitholestes langstoni\n",
      "854. Scaled Koi\n",
      "855. Scarab Beetle\n",
      "856. Scarab BP\n",
      "857. Scarab HP\n",
      "858. Scarab with Elytra\n",
      "859. Scorpion\n",
      "860. Scorpion HP\n",
      "861. Scorpion varileg\n",
      "862. Scrub Jay Nest\n",
      "863. Sea bream\n",
      "864. Sea Otter\n",
      "865. Sea Turtle\n",
      "866. Sea Urchin\n",
      "867. Seahorse\n",
      "868. Seed Pot\n",
      "869. SeedPot\n",
      "870. Shark\n",
      "871. Sheep\n",
      "872. shelter in place\n",
      "873. Shibaraku\n",
      "874. shibaraku head\n",
      "875. Shishapangma I\n",
      "876. Shizuoka Cicada\n",
      "877. Shizuoka Cicada and Cicada Nymph\n",
      "878. shoebill head\n",
      "879. shore crab\n",
      "880. short horned grasshopper\n",
      "881. shrimp\n",
      "882. shrimp v\n",
      "883. Shuki Kato\n",
      "884. Siam\n",
      "885. Siamese Fighting Fish\n",
      "886. siberian flying squirrel\n",
      "887. Silver Angel\n",
      "888. silver rectangle cockroach\n",
      "889. Silverfish\n",
      "890. Simple Dragon\n",
      "891. simple insects\n",
      "892. sindura shindara taisho\n",
      "893. Singer\n",
      "894. SingleSheet Pentasia\n",
      "895. SixDollar Burr\n",
      "896. SixDollar Orchid\n",
      "897. Skating Girl\n",
      "898. Skull\n",
      "899. Skunk\n",
      "900. sleeping cat\n",
      "901. sleipnir\n",
      "902. Slugs\n",
      "903. small chicken\n",
      "904. small elephant\n",
      "905. Smaug\n",
      "906. smilodon\n",
      "907. SmoothFaced Cube\n",
      "908. Snack Time\n",
      "909. snacktime\n",
      "910. Snail\n",
      "911. Snake\n",
      "912. Snakehead\n",
      "913. Soaring RedTailed Hawk\n",
      "914. Solenostomus cyanopterus\n",
      "915. Songbird\n",
      "916. Sparkle\n",
      "917. sparrow\n",
      "918. spider\n",
      "919. Spindle Murex\n",
      "920. Spinosaurus\n",
      "921. Spinosaurus aegyptiacus\n",
      "922. Spiny Lobster\n",
      "923. Spiral\n",
      "924. Splendid Garden Eel\n",
      "925. Sprite\n",
      "926. Squaring the Circle\n",
      "927. Squirrel\n",
      "928. st bernard\n",
      "929. Stag Beetle\n",
      "930. Stag Beetle BP\n",
      "931. Stardrop\n",
      "932. Stars and Stripes\n",
      "933. Steer\n",
      "934. Stegosaurus\n",
      "935. Sterling Poison Dart Frog\n",
      "936. Sthyracosaurus\n",
      "937. stink bug\n",
      "938. Stonefish\n",
      "939. study in squirrel tails\n",
      "940. Styracosaurus\n",
      "941. Summer Girl\n",
      "942. Summon\n",
      "943. sumo\n",
      "944. Sun\n",
      "945. sunflower\n",
      "946. Supersaurus viviane\n",
      "947. Surfing Girl\n",
      "948. SUV\n",
      "949. Swallow\n",
      "950. Swallowtail butterfly\n",
      "951. swan\n",
      "952. sword tail newt\n",
      "953. Sydney Opera House\n",
      "954. t rex\n",
      "955. t rex v\n",
      "956. Taiwan Goldfish\n",
      "957. Taiyaki\n",
      "958. tall figure\n",
      "959. Taoist priest\n",
      "960. Tapejara\n",
      "961. Tarantula\n",
      "962. Tarantula Terra\n",
      "963. Tatanka Ska\n",
      "964. Tecolote\n",
      "965. Telos\n",
      "966. Tengu\n",
      "967. tenma h\n",
      "968. TensionPot\n",
      "969. tess fish\n",
      "970. Tessellation\n",
      "971. Tetrahedral Truss\n",
      "972. Thataway\n",
      "973. The Beachcomber\n",
      "974. the foxs wedding\n",
      "975. the little clown\n",
      "976. The Old Man and the Old Woman\n",
      "977. The pioneer of Silk Road\n",
      "978. The Sentinel\n",
      "979. The Sentinel II\n",
      "980. The Victory of Samothrace\n",
      "981. the world eater\n",
      "982. Therizinosaurus\n",
      "983. thomsons gazelle\n",
      "984. thread sail filefish\n",
      "985. Threadsail filefish\n",
      "986. ThreeDollar Flower\n",
      "987. Tick\n",
      "988. Tiger\n",
      "989. Titan Beetle\n",
      "990. Tokyo Tower\n",
      "991. Torso\n",
      "992. Totoros\n",
      "993. Toucan\n",
      "994. TPost Generic Beetle\n",
      "995. Tran Trung Hieu\n",
      "996. tree\n",
      "997. Tree frog\n",
      "998. Treehopper\n",
      "999. Triceratop\n",
      "1000. Triceratops\n",
      "1001. Troodontid\n",
      "1002. Trumpet Vine Blossom\n",
      "1003. Truncated Tetrahedral Unit\n",
      "1004. tsuwamono\n",
      "1005. Tuna\n",
      "1006. Turbaned Man\n",
      "1007. Turkey\n",
      "1008. Turkey Vulture Richard\n",
      "1009. Turned Paper\n",
      "1010. Turtle\n",
      "1011. Two in the Bush\n",
      "1012. TwoLayer SevenFold Weave\n",
      "1013. Tyrannosaurus\n",
      "1014. Tyrannosaurus Skeleton\n",
      "1015. unicorn\n",
      "1016. UrnPot\n",
      "1017. UT\n",
      "1018. vajra basara taisho\n",
      "1019. Vajrapani\n",
      "1020. Valentine\n",
      "1021. Vase\n",
      "1022. Vegeta\n",
      "1023. veiltail angelfish\n",
      "1024. Velociraptor mongoliensis\n",
      "1025. Velociraptor skeleton\n",
      "1026. venus comb murex\n",
      "1027. Viking Ship\n",
      "1028. vinegaroon\n",
      "1029. Violin\n",
      "1030. Violinist\n",
      "1031. Violist\n",
      "1032. Vvanna girls\n",
      "1033. Walking in the rain\n",
      "1034. Warrior\n",
      "1035. Wasp\n",
      "1036. water buffalo\n",
      "1037. Water scorpion\n",
      "1038. Water Strider\n",
      "1039. weasel\n",
      "1040. Wedged DoubleFaced\n",
      "1041. Western Dragon\n",
      "1042. Western Pond Turtle\n",
      "1043. Whale shark\n",
      "1044. When Rebecca Met Shuzo\n",
      "1045. whip scorpion\n",
      "1046. Whip spider\n",
      "1047. white\n",
      "1048. White Bison bronze\n",
      "1049. White Bison medium\n",
      "1050. White Bison mini\n",
      "1051. White Bison monument\n",
      "1052. White Bison small\n",
      "1053. White Bison small medium\n",
      "1054. White Bison stainless\n",
      "1055. white cloud mountain minnow\n",
      "1056. white elephant\n",
      "1057. white leghorn\n",
      "1058. white owl\n",
      "1059. White Rhino\n",
      "1060. white rhinoceros\n",
      "1061. white tailed eagle\n",
      "1062. Whitetail Buck BP\n",
      "1063. Whitetail Doe BP\n",
      "1064. Whitetail Family BP\n",
      "1065. Whitetail Fawn\n",
      "1066. Whitetailed Deer\n",
      "1067. wild boar\n",
      "1068. Wild boar piglet\n",
      "1069. wild turkey\n",
      "1070. Willis Tower\n",
      "1071. winged kirin\n",
      "1072. witch mask\n",
      "1073. Wizard\n",
      "1074. Wizard and Dragon\n",
      "1075. Wolf\n",
      "1076. Wriothesley\n",
      "1077. Wyvern\n",
      "1078. Xenopus borealis\n",
      "1079. Yae Miko\n",
      "1080. yanbaru long armed scarab beetle\n",
      "1081. Yatagarasu\n",
      "1082. year of the bull\n",
      "1083. year of the mouse\n",
      "1084. Yebisu\n",
      "1085. Yellow Jacket\n",
      "1086. yellowtail farmed\n",
      "1087. yogen no tori bird of prophecy\n",
      "1088. zero fighter\n",
      "1089. zgok\n",
      "1090. Zoanoid Dragon\n",
      "\n",
      "Total folders: 1090\n"
     ]
    }
   ],
   "source": [
    "folder_names = list_all_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c97ab948-579d-4462-ba2e-e040b790d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WordNet-based canonical big-group classifier (minimal) === ## do this after dataset 2?\n",
    "\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# ensure wordnet is loaded (only if not already done)\n",
    "try:\n",
    "    _ = wn.synsets(\"cat\")\n",
    "except LookupError:\n",
    "    import nltk\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"omw-1.4\")\n",
    "\n",
    "# cached results for speed\n",
    "_WN_CACHE = {}\n",
    "_ANIMAL_ROOT = wn.synset(\"animal.n.01\")\n",
    "\n",
    "def _wn_is_animal_like(term: str) -> bool:\n",
    "    \"\"\"Check if a noun belongs under animal.n.01 in WordNet.\"\"\"\n",
    "    term = term.strip().lower().replace(\" \", \"_\")\n",
    "    if term in _WN_CACHE:\n",
    "        return _WN_CACHE[term]\n",
    "    syns = wn.synsets(term, pos=wn.NOUN)\n",
    "    for s in syns:\n",
    "        for anc in s.closure(lambda x: x.hypernyms()):\n",
    "            if anc == _ANIMAL_ROOT:\n",
    "                _WN_CACHE[term] = True\n",
    "                return True\n",
    "    _WN_CACHE[term] = False\n",
    "    return False\n",
    "\n",
    "DESCRIPTORS = {\n",
    "    \"african\",\"asian\",\"american\",\"australian\",\"arctic\",\"antarctic\",\"snow\",\"white\",\"black\",\"red\",\n",
    "    \"golden\",\"silver\",\"greater\",\"lesser\",\"giant\",\"baby\",\"wild\",\"common\",\"domestic\",\"horned\",\"tailed\",\n",
    "    \"short\",\"long\",\"great\",\"little\",\"flying\",\"sitting\",\"standing\",\"walking\",\"running\",\"resting\",\n",
    "    \"in\",\"on\",\"and\",\"of\",\"the\",\"with\",\"for\",\"from\"\n",
    "}\n",
    "\n",
    "SYNONYMS = {\n",
    "    \"snow leopard\": \"leopard\",\n",
    "    \"white leopard\": \"leopard\",\n",
    "    \"panther\": \"leopard\",\n",
    "    \"african elephant\": \"elephant\",\n",
    "    \"asian elephant\": \"elephant\",\n",
    "    \"asiatic elephant\": \"elephant\",\n",
    "    \"flying fox\": \"fox\",\n",
    "    \"ladybird\": \"ladybug\",\n",
    "    \"ladybird beetle\": \"ladybug\",\n",
    "    \"sea bream\": \"seabream\",\n",
    "    \"red sea bream\": \"seabream\",\n",
    "    \"orca\": \"whale\",\n",
    "    \"killer whale\": \"whale\",\n",
    "}\n",
    "\n",
    "MULTIWORD_KEEP = {\n",
    "    \"sea lion\",\"sea otter\",\"sea turtle\",\"praying mantis\",\"stick insect\",\"wolf spider\",\"garden spider\"\n",
    "}\n",
    "\n",
    "def _letters_only_lower(s: str) -> str:\n",
    "    runs = re.findall(r\"[A-Za-z]+\", s)\n",
    "    return \" \".join(r.lower() for r in runs).strip()\n",
    "\n",
    "def _canonical_big_group(label: str) -> str | None:\n",
    "    \"\"\"Map folder name to big-group canonical animal name using WordNet.\"\"\"\n",
    "    s = _letters_only_lower(label)\n",
    "    if not s:\n",
    "        return None\n",
    "\n",
    "    # synonym direct\n",
    "    if s in SYNONYMS:\n",
    "        s = SYNONYMS[s]\n",
    "        return s if (_wn_is_animal_like(s) or s in MULTIWORD_KEEP) else None\n",
    "    if s in MULTIWORD_KEEP:\n",
    "        return s\n",
    "\n",
    "    # remove descriptors\n",
    "    tokens = [t for t in s.split() if t not in DESCRIPTORS]\n",
    "    if not tokens:\n",
    "        return None\n",
    "\n",
    "    # bigram check (rightmost)\n",
    "    if len(tokens) >= 2:\n",
    "        bigram = f\"{tokens[-2]} {tokens[-1]}\"\n",
    "        if bigram in SYNONYMS:\n",
    "            cand = SYNONYMS[bigram]\n",
    "            return cand if (_wn_is_animal_like(cand) or cand in MULTIWORD_KEEP) else None\n",
    "        if bigram in MULTIWORD_KEEP:\n",
    "            return bigram\n",
    "        if _wn_is_animal_like(bigram):\n",
    "            return bigram\n",
    "\n",
    "    # head noun\n",
    "    head = tokens[-1]\n",
    "    if head in SYNONYMS:\n",
    "        head = SYNONYMS[head]\n",
    "    if _wn_is_animal_like(head):\n",
    "        return head\n",
    "\n",
    "    reduced = \" \".join(tokens)\n",
    "    if reduced in SYNONYMS:\n",
    "        reduced = SYNONYMS[reduced]\n",
    "    if _wn_is_animal_like(reduced):\n",
    "        return reduced\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e8d38b0-d750-410a-a246-87d50d59603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL VERSION: Filter to animals/birds/insects and DELETE all others ===\n",
    "def filter_animals_biggroup_wordnet(work_dir=WORK_DIR, log_dir=LOG_DIR, dry_run=True):\n",
    "    work_dir = Path(work_dir)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    staging_root = work_dir / \"_animals_buckets\"\n",
    "\n",
    "    before_images = count_images(work_dir)\n",
    "    src_dirs = [d for d in work_dir.iterdir() if d.is_dir() and d.name != staging_root.name]\n",
    "\n",
    "    mode = \"DRY-RUN\" if dry_run else \"EXECUTE\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_csv = log_dir / f\"filter_animals_wordnet_{mode}_{ts}.csv\"\n",
    "\n",
    "    planned_buckets, planned_moves, planned_drops, collisions = set(), [], [], []\n",
    "\n",
    "    for d in sorted(src_dirs, key=lambda p: p.name.lower()):\n",
    "        group = _canonical_big_group(d.name)\n",
    "        if not group:\n",
    "            planned_drops.append(d)\n",
    "            continue\n",
    "        bucket = staging_root / group\n",
    "        planned_buckets.add(bucket)\n",
    "        for src in [p for p in d.rglob(\"*\") if p.is_file()]:\n",
    "            dst = bucket / src.name\n",
    "            if dst.exists():\n",
    "                new_dst = bucket / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                collisions.append((dst, new_dst))\n",
    "                dst = new_dst\n",
    "            planned_moves.append((src, dst, d, bucket, group))\n",
    "\n",
    "    print(f\"\\n[WORDNET FILTER + CLEANUP ‚Äî {mode}]\")\n",
    "    print(f\"Folders scanned  : {len(src_dirs)}\")\n",
    "    print(f\"Animal groups    : {len(planned_buckets)}\")\n",
    "    print(f\"Files to keep    : {len(planned_moves)}\")\n",
    "    print(f\"Non-animal drops : {len(planned_drops)}\")\n",
    "    print(f\"üßæ Log: {log_csv}\")\n",
    "\n",
    "    if dry_run:\n",
    "        print(\"\\nüí° Dry-run only. No changes applied.\")\n",
    "        print(f\"üñºÔ∏è Image count (WORK_DIR): {before_images}\")\n",
    "        return\n",
    "\n",
    "    # --- EXECUTE ---\n",
    "    # 1. Create staging buckets\n",
    "    for b in sorted(planned_buckets):\n",
    "        b.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 2. Move all animal/insect/bird files\n",
    "    kept = 0\n",
    "    for src, dst, sdir, bdir, grp in planned_moves:\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(str(src), str(dst))\n",
    "        kept += 1\n",
    "\n",
    "    # 3. DELETE all non-animal folders\n",
    "    removed_non_animals = 0\n",
    "    for d in planned_drops:\n",
    "        try:\n",
    "            shutil.rmtree(d)\n",
    "            removed_non_animals += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not delete {d}: {e}\")\n",
    "\n",
    "    # 4. Remove emptied originals (even if they had animals)\n",
    "    for d in sorted(src_dirs, key=lambda p: len(p.parts), reverse=True):\n",
    "        if not d.exists() or d == staging_root:\n",
    "            continue\n",
    "        try:\n",
    "            if not any(d.iterdir()):\n",
    "                d.rmdir()\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    # 5. Promote buckets to top level\n",
    "    promoted = 0\n",
    "    for b in sorted(staging_root.iterdir()):\n",
    "        if not b.is_dir(): continue\n",
    "        final = work_dir / b.name\n",
    "        if final.exists() and final != b:\n",
    "            for src in [p for p in b.rglob(\"*\") if p.is_file()]:\n",
    "                dst = final / src.name\n",
    "                if dst.exists():\n",
    "                    dst = final / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                shutil.move(str(src), str(dst))\n",
    "            shutil.rmtree(b)\n",
    "        else:\n",
    "            b.rename(final)\n",
    "        promoted += 1\n",
    "\n",
    "    try:\n",
    "        staging_root.rmdir()\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    after_images = count_images(work_dir)\n",
    "    print(f\"\\n‚úÖ Executed.\")\n",
    "    print(f\" ‚Ä¢ Files kept (animals/insects/birds): {kept}\")\n",
    "    print(f\" ‚Ä¢ Non-animal folders deleted        : {removed_non_animals}\")\n",
    "    print(f\" ‚Ä¢ Buckets promoted                  : {promoted}\")\n",
    "    print(f\"üñºÔ∏è Image count (WORK_DIR): {after_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af7ff9cc-87c7-42bb-b42e-a44fe79b18e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WORDNET FILTER + CLEANUP ‚Äî DRY-RUN]\n",
      "Folders scanned  : 919\n",
      "Animal groups    : 296\n",
      "Files to keep    : 1722\n",
      "Non-animal drops : 623\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/filter_animals_wordnet_DRY-RUN_20251013_163556.csv\n",
      "\n",
      "üí° Dry-run only. No changes applied.\n",
      "üñºÔ∏è Image count (WORK_DIR): 3476\n"
     ]
    }
   ],
   "source": [
    "filter_animals_biggroup_wordnet(dry_run=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65cc7a8b-414d-4207-856e-4a1ba9a5977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WORDNET FILTER + CLEANUP ‚Äî EXECUTE]\n",
      "Folders scanned  : 919\n",
      "Animal groups    : 296\n",
      "Files to keep    : 1722\n",
      "Non-animal drops : 623\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/filter_animals_wordnet_EXECUTE_20251013_163600.csv\n",
      "\n",
      "‚úÖ Executed.\n",
      " ‚Ä¢ Files kept (animals/insects/birds): 1722\n",
      " ‚Ä¢ Non-animal folders deleted        : 623\n",
      " ‚Ä¢ Buckets promoted                  : 296\n",
      "üñºÔ∏è Image count (WORK_DIR): 1721\n"
     ]
    }
   ],
   "source": [
    "filter_animals_biggroup_wordnet(dry_run=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d9cac-113f-4d11-a99f-4ba9a9f6ec31",
   "metadata": {},
   "source": [
    "### Dataset 2: removing all non animal folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94e0b660-3807-4ea5-b0e7-6fcb2b18c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, csv, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# RAW2 root (adjust if needed)\n",
    "RAW2_DIR = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/original data/origami-model\")\n",
    "\n",
    "def import_dataset2_merge_simple(\n",
    "    raw2_dir=RAW2_DIR,\n",
    "    work_dir=WORK_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    dry_run=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Dataset 2 import WITHOUT big-grouping:\n",
    "      - Drop category layer (animals/, insects/, etc.)\n",
    "      - Skip categories: characters, objects, shapes, unclassified\n",
    "      - Canonicalize leaf names via _canonicalize_name(name)\n",
    "      - Merge into WORK_DIR (keep all files; hash on collisions)\n",
    "      - macOS-safe via staging buckets\n",
    "      - Print image counts before/after\n",
    "    \"\"\"\n",
    "    raw2_dir = Path(raw2_dir)\n",
    "    work_dir = Path(work_dir)\n",
    "    log_dir = Path(log_dir); log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    staging_root = work_dir / \"_import2_buckets_simple\"\n",
    "\n",
    "    if not raw2_dir.exists():\n",
    "        raise FileNotFoundError(f\"RAW2_DIR does not exist: {raw2_dir}\")\n",
    "\n",
    "    # categories to ignore entirely\n",
    "    drop_cats = {\"characters\", \"objects\", \"shapes\", \"unclassified\"}\n",
    "    top_level = [d for d in raw2_dir.iterdir() if d.is_dir()]\n",
    "    allowed_cats = [d for d in top_level if d.name.lower() not in drop_cats]\n",
    "\n",
    "    before_images = count_images(work_dir)\n",
    "\n",
    "    mode = \"DRY-RUN\" if dry_run else \"EXECUTE\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_csv = log_dir / f\"import_dataset2_simple_{mode}_{ts}.csv\"\n",
    "\n",
    "    planned_buckets = set()\n",
    "    planned_moves = []   # (src_file, dst_file, src_leaf_dir, bucket_dir, canonical)\n",
    "    planned_skips  = []  # (leaf_dir, reason)\n",
    "    collisions = []\n",
    "\n",
    "    # helper: canonicalize via your existing function\n",
    "    def _canon_leaf(name: str) -> str | None:\n",
    "        try:\n",
    "            canon = _canonicalize_name(name)  # already in your notebook\n",
    "            return canon or None\n",
    "        except NameError:\n",
    "            # minimal fallback if needed\n",
    "            import re\n",
    "            runs = re.findall(r\"[A-Za-z]+\", name)\n",
    "            canon = \" \".join(r.lower() for r in runs).strip()\n",
    "            return canon or None\n",
    "\n",
    "    # walk allowed categories; each subdir is a leaf (animal/insect/etc. name)\n",
    "    for cat in sorted(allowed_cats, key=lambda p: p.name.lower()):\n",
    "        for leaf in sorted([d for d in cat.iterdir() if d.is_dir()], key=lambda p: p.name.lower()):\n",
    "            canon = _canon_leaf(leaf.name)\n",
    "            if not canon:\n",
    "                planned_skips.append((leaf, \"canonicalization->None\"))\n",
    "                continue\n",
    "\n",
    "            bucket = staging_root / canon\n",
    "            planned_buckets.add(bucket)\n",
    "\n",
    "            for src in [p for p in leaf.rglob(\"*\") if p.is_file()]:\n",
    "                dst = bucket / src.name\n",
    "                if dst.exists():\n",
    "                    # use your hash helper already defined\n",
    "                    new_dst = bucket / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                    collisions.append((dst, new_dst))\n",
    "                    dst = new_dst\n",
    "                planned_moves.append((src, dst, leaf, bucket, canon))\n",
    "\n",
    "    # log + preview\n",
    "    with open(log_csv, \"w\", newline=\"\") as fp:\n",
    "        w = csv.writer(fp)\n",
    "        w.writerow([\"action\",\"src\",\"dst\",\"extra\"])\n",
    "        for b in sorted(planned_buckets):\n",
    "            w.writerow([\"create_bucket\", \"\", str(b), b.name])\n",
    "        for src, dst, sdir, bdir, canon in planned_moves:\n",
    "            w.writerow([\"move_to_bucket\", str(src), str(dst), canon])\n",
    "        for (orig, new) in collisions:\n",
    "            w.writerow([\"collision_rename_file\", str(orig), str(new), \"\"])\n",
    "        for (leaf, reason) in planned_skips:\n",
    "            w.writerow([\"skip_leaf\", str(leaf), \"\", reason])\n",
    "\n",
    "    print(f\"\\n[IMPORT DATASET 2 (simple) ‚Äî {mode}]\")\n",
    "    print(f\"Allowed categories        : {len(allowed_cats)}\")\n",
    "    print(f\"Canonical buckets         : {len(planned_buckets)}\")\n",
    "    print(f\"Files to move (keep)      : {len(planned_moves)}\")\n",
    "    print(f\"Leaf folders skipped      : {len(planned_skips)}\")\n",
    "    print(f\"Filename collisions       : {len(collisions)}\")\n",
    "    print(f\"üñºÔ∏è Images in WORK before  : {before_images}\")\n",
    "    print(f\"üßæ Log: {log_csv}\")\n",
    "\n",
    "    # sample\n",
    "    for i, (src, dst, sdir, bdir, canon) in enumerate(planned_moves[:12]):\n",
    "        print(f\"  {sdir.name} ‚Üí {canon}: {src.name}\")\n",
    "    for i, (leaf, why) in enumerate(planned_skips[:8]):\n",
    "        print(f\"  SKIP: {leaf.name} ({why})\")\n",
    "\n",
    "    if dry_run:\n",
    "        print(\"\\nüí° Dry-run only. No changes applied.\")\n",
    "        return {\n",
    "            \"planned_buckets\": len(planned_buckets),\n",
    "            \"planned_moves\": len(planned_moves),\n",
    "            \"planned_skips\": len(planned_skips),\n",
    "            \"collisions\": len(collisions),\n",
    "            \"log_csv\": log_csv,\n",
    "            \"images_before\": before_images\n",
    "        }\n",
    "\n",
    "    # EXECUTE: create buckets & move files from RAW2 into staging buckets\n",
    "    for b in sorted(planned_buckets):\n",
    "        b.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    moved = 0\n",
    "    for src, dst, sdir, bdir, canon in planned_moves:\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(str(src), str(dst))\n",
    "        moved += 1\n",
    "\n",
    "    # merge buckets into WORK_DIR\n",
    "    promoted = 0\n",
    "    for b in sorted(staging_root.iterdir()):\n",
    "        if not b.is_dir():\n",
    "            continue\n",
    "        final = work_dir / b.name  # canonical (letters-only, lowercase)\n",
    "        if final.exists() and final != b:\n",
    "            # merge contents\n",
    "            for src in [p for p in b.rglob(\"*\") if p.is_file()]:\n",
    "                dst = final / src.name\n",
    "                if dst.exists():\n",
    "                    dst = final / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(str(src), str(dst))\n",
    "            shutil.rmtree(b)\n",
    "            promoted += 1\n",
    "        else:\n",
    "            b.rename(final)\n",
    "            promoted += 1\n",
    "\n",
    "    # clean staging root if empty\n",
    "    try:\n",
    "        staging_root.rmdir()\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    after_images = count_images(work_dir)\n",
    "    print(f\"\\n‚úÖ Executed.\")\n",
    "    print(f\" ‚Ä¢ Files moved from RAW2 : {moved}\")\n",
    "    print(f\" ‚Ä¢ Buckets merged/promoted: {promoted}\")\n",
    "    print(f\"üñºÔ∏è Images in WORK after   : {after_images}\")\n",
    "\n",
    "    return {\n",
    "        \"moved_files\": moved,\n",
    "        \"promoted_buckets\": promoted,\n",
    "        \"log_csv\": log_csv,\n",
    "        \"images_before\": before_images,\n",
    "        \"images_after\": after_images\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3373ed2-34f3-4a79-8adf-d47b8b644de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IMPORT DATASET 2 (simple) ‚Äî DRY-RUN]\n",
      "Allowed categories        : 4\n",
      "Canonical buckets         : 64\n",
      "Files to move (keep)      : 3482\n",
      "Leaf folders skipped      : 0\n",
      "Filename collisions       : 0\n",
      "üñºÔ∏è Images in WORK before  : 1721\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/import_dataset2_simple_DRY-RUN_20251013_165403.csv\n",
      "  armadillo ‚Üí armadillo: p_armadillo_szinger_sculpture.jpg\n",
      "  armadillo ‚Üí armadillo: 34381.jpg\n",
      "  armadillo ‚Üí armadillo: p_armadillo_wu.jpg\n",
      "  armadillo ‚Üí armadillo: 2400.jpg\n",
      "  armadillo ‚Üí armadillo: p_armadillo_yamaguchi_cute.jpg\n",
      "  armadillo ‚Üí armadillo: 2147.jpg\n",
      "  armadillo ‚Üí armadillo: 2133.jpg\n",
      "  armadillo ‚Üí armadillo: p_armadillo_fuchimoto_pet_park.jpg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115230.138.jpeg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115229.619.jpeg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115227.764.jpeg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115230.883.jpeg\n",
      "\n",
      "üí° Dry-run only. No changes applied.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'planned_buckets': 64,\n",
       " 'planned_moves': 3482,\n",
       " 'planned_skips': 0,\n",
       " 'collisions': 0,\n",
       " 'log_csv': PosixPath('/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/import_dataset2_simple_DRY-RUN_20251013_165403.csv'),\n",
       " 'images_before': 1721}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_dataset2_merge_simple(dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8936ac8e-7804-412a-9026-9864f9898a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IMPORT DATASET 2 (simple) ‚Äî EXECUTE]\n",
      "Allowed categories        : 4\n",
      "Canonical buckets         : 64\n",
      "Files to move (keep)      : 3482\n",
      "Leaf folders skipped      : 0\n",
      "Filename collisions       : 0\n",
      "üñºÔ∏è Images in WORK before  : 1721\n",
      "üßæ Log: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/import_dataset2_simple_EXECUTE_20251013_165425.csv\n",
      "  armadillo ‚Üí armadillo: p_armadillo_szinger_sculpture.jpg\n",
      "  armadillo ‚Üí armadillo: 34381.jpg\n",
      "  armadillo ‚Üí armadillo: p_armadillo_wu.jpg\n",
      "  armadillo ‚Üí armadillo: 2400.jpg\n",
      "  armadillo ‚Üí armadillo: p_armadillo_yamaguchi_cute.jpg\n",
      "  armadillo ‚Üí armadillo: 2147.jpg\n",
      "  armadillo ‚Üí armadillo: 2133.jpg\n",
      "  armadillo ‚Üí armadillo: p_armadillo_fuchimoto_pet_park.jpg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115230.138.jpeg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115229.619.jpeg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115227.764.jpeg\n",
      "  bear ‚Üí bear: th - 2023-11-25T115230.883.jpeg\n",
      "\n",
      "‚úÖ Executed.\n",
      " ‚Ä¢ Files moved from RAW2 : 3482\n",
      " ‚Ä¢ Buckets merged/promoted: 64\n",
      "üñºÔ∏è Images in WORK after   : 5203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'moved_files': 3482,\n",
       " 'promoted_buckets': 64,\n",
       " 'log_csv': PosixPath('/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/import_dataset2_simple_EXECUTE_20251013_165425.csv'),\n",
       " 'images_before': 1721,\n",
       " 'images_after': 5203}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_dataset2_merge_simple(dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4ec15-89cd-4e1f-9cb6-0c9db10e9457",
   "metadata": {},
   "source": [
    "### Compiled Dataset: Remove scientific names and merge mirco classes into big groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3069101-a235-4d10-b17d-b92df184dce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Listing all folders in: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\n",
      "\n",
      "\n",
      "Total folders: 0\n"
     ]
    }
   ],
   "source": [
    "folder_names = list_all_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8788e36-8b27-41a6-b61f-bc8b03b10298",
   "metadata": {},
   "source": [
    "#### at this point went manually in to converge groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17b825ce-def1-4200-af73-956f22cbde9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Total images in WORK_DIR (work): 4842\n"
     ]
    }
   ],
   "source": [
    "final_image_count = count_images(WORK_DIR)\n",
    "print(f\"üñºÔ∏è Total images in WORK_DIR ({WORK_DIR.name}): {final_image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21b5b43e-2d1a-45e1-9dbe-4414d9702a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Image count per folder in work:\n",
      "\n",
      "üñºÔ∏è Total images in WORK_DIR (work): 0\n"
     ]
    }
   ],
   "source": [
    "folder_image_counts = count_images_in_each_folder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e6f905b-f2dc-44b7-b5b9-7e3ecc12183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil, os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "def transfer_to_clean_final(\n",
    "    work_dir=WORK_DIR,\n",
    "    clean_dir=CLEAN_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    subfolder_name=\"origami_images\",\n",
    "    dry_run=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Move all images/folders from WORK_DIR ‚Üí CLEAN_DIR/<subfolder_name>.\n",
    "    - Creates subfolder under CLEAN_DIR (default: 'origami_images').\n",
    "    - Preserves subfolder structure inside.\n",
    "    - Appends hash on duplicate filenames.\n",
    "    - Logs a CSV of all moves.\n",
    "    - Deletes everything inside WORK_DIR after transfer (if not dry_run).\n",
    "    \"\"\"\n",
    "    work_dir = Path(work_dir)\n",
    "    clean_dir = Path(clean_dir)\n",
    "    target_dir = clean_dir / subfolder_name\n",
    "    log_dir = Path(log_dir)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    before_work = count_images(work_dir)\n",
    "    before_clean = count_images(target_dir)\n",
    "    mode = \"DRY-RUN\" if dry_run else \"EXECUTE\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_csv = log_dir / f\"transfer_to_clean_{mode}_{ts}.csv\"\n",
    "\n",
    "    moved, collisions = 0, 0\n",
    "    planned_moves = []\n",
    "\n",
    "    # Plan every file move\n",
    "    for root, _, files in os.walk(work_dir):\n",
    "        rel = Path(root).relative_to(work_dir)\n",
    "        for f in files:\n",
    "            src = Path(root) / f\n",
    "            dst = target_dir / rel / f\n",
    "            if dst.exists():\n",
    "                new_dst = target_dir / rel / f\"{dst.stem}__{_sha1_short(src)}{dst.suffix}\"\n",
    "                dst = new_dst\n",
    "                collisions += 1\n",
    "            planned_moves.append((src, dst))\n",
    "\n",
    "    # Write log CSV\n",
    "    with open(log_csv, \"w\", newline=\"\") as fp:\n",
    "        w = csv.writer(fp)\n",
    "        w.writerow([\"src_path\", \"dst_path\"])\n",
    "        w.writerows([(str(s), str(d)) for s, d in planned_moves])\n",
    "\n",
    "    print(f\"\\n[TRANSFER TO CLEAN/{subfolder_name} ‚Äî {mode}]\")\n",
    "    print(f\"üñºÔ∏è Images in WORK_DIR before: {before_work}\")\n",
    "    print(f\"üñºÔ∏è Images in CLEAN_DIR before: {before_clean}\")\n",
    "    print(f\"Files to move: {len(planned_moves)}  (collisions handled: {collisions})\")\n",
    "    print(f\"üßæ Log CSV: {log_csv}\")\n",
    "\n",
    "    if dry_run:\n",
    "        print(\"\\nüí° Dry-run only. No files moved.\")\n",
    "        return\n",
    "\n",
    "    # Execute actual move\n",
    "    for src, dst in planned_moves:\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(str(src), str(dst))\n",
    "        moved += 1\n",
    "\n",
    "    # Delete everything in WORK_DIR\n",
    "    for item in work_dir.iterdir():\n",
    "        try:\n",
    "            if item.is_dir():\n",
    "                shutil.rmtree(item)\n",
    "            else:\n",
    "                item.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not delete {item}: {e}\")\n",
    "\n",
    "    after_work = count_images(work_dir)\n",
    "    after_clean = count_images(target_dir)\n",
    "\n",
    "    print(f\"\\n‚úÖ Executed transfer.\")\n",
    "    print(f\" ‚Ä¢ Files moved        : {moved}\")\n",
    "    print(f\" ‚Ä¢ Collisions handled : {collisions}\")\n",
    "    print(f\" ‚Ä¢ Emptied WORK_DIR   : {work_dir}\")\n",
    "    print(f\"üñºÔ∏è Images in CLEAN/origami_images now : {after_clean}\")\n",
    "    print(f\"üßæ Log file saved at  : {log_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8edbef5d-eab0-4e85-845d-fc2b0b194f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRANSFER TO CLEAN/origami_images ‚Äî DRY-RUN]\n",
      "üñºÔ∏è Images in WORK_DIR before: 4842\n",
      "üñºÔ∏è Images in CLEAN_DIR before: 0\n",
      "Files to move: 4849  (collisions handled: 0)\n",
      "üßæ Log CSV: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/transfer_to_clean_DRY-RUN_20251023_143452.csv\n",
      "\n",
      "üí° Dry-run only. No files moved.\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Dry-run first (just shows the plan and counts)\n",
    "transfer_to_clean_final(dry_run=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fa27569-8051-4d9a-b525-da2e2f4f41dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRANSFER TO CLEAN/origami_images ‚Äî EXECUTE]\n",
      "üñºÔ∏è Images in WORK_DIR before: 4842\n",
      "üñºÔ∏è Images in CLEAN_DIR before: 0\n",
      "Files to move: 4849  (collisions handled: 0)\n",
      "üßæ Log CSV: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/transfer_to_clean_EXECUTE_20251023_143458.csv\n",
      "\n",
      "‚úÖ Executed transfer.\n",
      " ‚Ä¢ Files moved        : 4849\n",
      " ‚Ä¢ Collisions handled : 0\n",
      " ‚Ä¢ Emptied WORK_DIR   : /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/work\n",
      "üñºÔ∏è Images in CLEAN/origami_images now : 4842\n",
      "üßæ Log file saved at  : /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/_logs/transfer_to_clean_EXECUTE_20251023_143458.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2Ô∏è‚É£ Execute for real (move files and folders)\n",
    "transfer_to_clean_final(dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f3ae971-5d58-4f3d-a507-ad21fb484852",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38c37792-1373-4ac2-a212-659b6f4ea446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMAGENET MAPPING: folder names -> closest wnid from word.txt ===\n",
    "from pathlib import Path\n",
    "import re, csv, os\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---- Config ----\n",
    "WORD_TXT_PATH = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/words.txt\")  # <-- set this!\n",
    "CLASSES_DIR   = CLEAN_DIR / \"origami_images\"  # where your final class folders live\n",
    "DATA_DIR      = CLEAN_DIR.parent             # \"data folder\" = the dataset root that contains 'clean'\n",
    "OUT_CSV       = DATA_DIR / \"imagenet_mappings.csv\"\n",
    "\n",
    "# ---- Optional: RapidFuzz (preferred), else fallback to difflib ----\n",
    "try:\n",
    "    from rapidfuzz import fuzz\n",
    "    _USE_RF = True\n",
    "except Exception:\n",
    "    import difflib\n",
    "    _USE_RF = False\n",
    "\n",
    "# ---- Normalization helpers ----\n",
    "def _letters_only_lower(s: str) -> str:\n",
    "    runs = re.findall(r\"[A-Za-z]+\", s)\n",
    "    return \" \".join(r.lower() for r in runs).strip()\n",
    "\n",
    "def _singularize_basic(tok: str) -> str:\n",
    "    irr = {\"wolves\":\"wolf\",\"geese\":\"goose\",\"mice\":\"mouse\",\"teeth\":\"tooth\",\"feet\":\"foot\",\"oxen\":\"ox\",\"deer\":\"deer\",\"elk\":\"elk\"}\n",
    "    if tok in irr: return irr[tok]\n",
    "    if len(tok) > 3 and tok.endswith(\"s\") and not tok.endswith((\"ss\",\"us\")):\n",
    "        return tok[:-1]\n",
    "    return tok\n",
    "\n",
    "def _norm_phrase(s: str) -> str:\n",
    "    toks = [_singularize_basic(t) for t in _letters_only_lower(s).split()]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "# ---- Parse ImageNet word.txt ----\n",
    "def load_imagenet_labels(word_txt: Path):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      entries: list of (wnid, raw_label, norm_label)\n",
    "      by_wnid: dict wnid -> {\"raw\": raw_line, \"labels\": [raw_label, ...], \"norm_labels\":[...]}\n",
    "    Accepts typical lines like:\n",
    "      n01440764 tench, Tinca tinca\n",
    "      n02119789 kit fox, Vulpes macrotis\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    by_wnid = defaultdict(lambda: {\"raw\": \"\", \"labels\": [], \"norm_labels\": []})\n",
    "    with open(word_txt, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fp:\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            # extract wnid (first token like n########)\n",
    "            m = re.match(r\"^(n\\d{8})\\s+(.+)$\", line)\n",
    "            if not m:\n",
    "                # sometimes tab-separated\n",
    "                m = re.match(r\"^(n\\d{8})\\t(.+)$\", line)\n",
    "            if not m:\n",
    "                continue\n",
    "            wnid, labels_part = m.group(1), m.group(2)\n",
    "\n",
    "            # split synonyms by comma\n",
    "            raw_labels = [lbl.strip() for lbl in labels_part.split(\",\") if lbl.strip()]\n",
    "            norm_labels = [_norm_phrase(lbl) for lbl in raw_labels]\n",
    "\n",
    "            for rl, nl in zip(raw_labels, norm_labels):\n",
    "                entries.append((wnid, rl, nl))\n",
    "\n",
    "            rec = by_wnid[wnid]\n",
    "            if not rec[\"raw\"]: rec[\"raw\"] = line\n",
    "            rec[\"labels\"].extend(raw_labels)\n",
    "            rec[\"norm_labels\"].extend(norm_labels)\n",
    "    return entries, by_wnid\n",
    "\n",
    "# ---- Build a flat search list and a quick inverted index by normalized label ----\n",
    "def build_search_index(entries):\n",
    "    \"\"\"\n",
    "    entries: list of (wnid, raw_label, norm_label)\n",
    "    returns:\n",
    "      flat: list of dicts with {\"wnid\",\"raw\",\"norm\"}\n",
    "      exact_map: dict norm_label -> set(wnid)\n",
    "    \"\"\"\n",
    "    flat = [{\"wnid\": wnid, \"raw\": raw, \"norm\": norm} for wnid, raw, norm in entries]\n",
    "    exact_map = defaultdict(set)\n",
    "    for e in flat:\n",
    "        if e[\"norm\"]:\n",
    "            exact_map[e[\"norm\"]].add(e[\"wnid\"])\n",
    "    return flat, exact_map\n",
    "\n",
    "# ---- Similarity scoring ----\n",
    "def _score(a: str, b: str) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    if _USE_RF:\n",
    "        return float(fuzz.token_set_ratio(a, b))\n",
    "    # difflib fallback (scale ~0..100)\n",
    "    return 100.0 * difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ---- Main mapping function ----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a1ce1e4-b46d-4aae-afec-638b11716bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_folders_to_imagenet(\n",
    "    classes_dir: Path = CLEAN_DIR / \"origami_images\",\n",
    "    word_txt: Path = WORD_TXT_PATH,\n",
    "    out_csv: Path = DATA_DIR / \"imagenet_mappings_full.csv\",\n",
    "    fuzzy_threshold: float = 70.0,\n",
    "    topk: int = 3\n",
    "):\n",
    "    \"\"\"\n",
    "    For each folder in classes_dir:\n",
    "      - finds best matching ImageNet wnid\n",
    "      - includes all labels (synonyms) for that wnid in the CSV\n",
    "    Output columns:\n",
    "      folder_name, wnid, main_label, all_labels, score, match_type, alt_candidates\n",
    "    \"\"\"\n",
    "    assert word_txt.exists(), f\"word.txt not found: {word_txt}\"\n",
    "    classes_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    entries, by_wnid = load_imagenet_labels(word_txt)\n",
    "    flat, exact_map = build_search_index(entries)\n",
    "\n",
    "    folders = [p.name for p in classes_dir.iterdir() if p.is_dir()]\n",
    "    rows = []\n",
    "\n",
    "    for cls in sorted(folders, key=str.lower):\n",
    "        q_raw  = cls\n",
    "        q_norm = _norm_phrase(q_raw)\n",
    "\n",
    "        # --- 1) Exact match ---\n",
    "        exact_wnids = exact_map.get(q_norm, set())\n",
    "        if exact_wnids:\n",
    "            chosen = sorted(exact_wnids)[0]\n",
    "            all_labels = \", \".join(by_wnid[chosen][\"labels\"])\n",
    "            main_label = by_wnid[chosen][\"labels\"][0] if by_wnid[chosen][\"labels\"] else \"\"\n",
    "            rows.append([q_raw, chosen, main_label, all_labels, 100.0, \"exact\", \"\"])\n",
    "            continue\n",
    "\n",
    "        # --- 2) Fuzzy match ---\n",
    "        best = []\n",
    "        for e in flat:\n",
    "            sc = _score(q_norm, e[\"norm\"])\n",
    "            best.append((sc, e[\"wnid\"], e[\"raw\"]))\n",
    "        best.sort(reverse=True)\n",
    "        if best:\n",
    "            top = best[0]\n",
    "            score, wnid, rlabel = top\n",
    "            all_labels = \", \".join(by_wnid[wnid][\"labels\"])\n",
    "            alts = \"; \".join([f\"{wn}:{lb} ({int(sc)})\" for sc, wn, lb in best[:topk]])\n",
    "            if score >= fuzzy_threshold:\n",
    "                rows.append([q_raw, wnid, rlabel, all_labels, float(score), \"fuzzy\", alts])\n",
    "            else:\n",
    "                rows.append([q_raw, \"\", \"\", \"\", float(score), \"low_score\", alts])\n",
    "        else:\n",
    "            rows.append([q_raw, \"\", \"\", \"\", 0.0, \"no_candidates\", \"\"])\n",
    "\n",
    "    # --- Write CSV ---\n",
    "    with open(out_csv, \"w\", newline=\"\") as fp:\n",
    "        w = csv.writer(fp)\n",
    "        w.writerow([\n",
    "            \"folder_name\", \"wnid\", \"main_label\", \"all_labels\",\n",
    "            \"score\", \"match_type\", \"alt_candidates\"\n",
    "        ])\n",
    "        w.writerows(rows)\n",
    "\n",
    "    # --- Summary ---\n",
    "    exact = sum(1 for r in rows if r[5] == \"exact\")\n",
    "    fuzzy = sum(1 for r in rows if r[5] == \"fuzzy\")\n",
    "    low   = sum(1 for r in rows if r[5] == \"low_score\")\n",
    "    none  = sum(1 for r in rows if r[5] == \"no_candidates\")\n",
    "    print(f\"\\n[IMAGENET MAPPING ‚Äî FULL LABELS]\")\n",
    "    print(f\"Classes scanned     : {len(rows)}\")\n",
    "    print(f\"Exact matches       : {exact}\")\n",
    "    print(f\"Fuzzy matches       : {fuzzy}\")\n",
    "    print(f\"Below threshold     : {low}\")\n",
    "    print(f\"No candidates       : {none}\")\n",
    "    print(f\"üßæ CSV saved to     : {out_csv}\")\n",
    "\n",
    "    return {\"csv\": out_csv, \"total\": len(rows), \"exact\": exact, \"fuzzy\": fuzzy, \"low\": low, \"none\": none}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3db13d28-d5d9-47a2-8f78-f9a2ba81826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IMAGENET MAPPING ‚Äî FULL LABELS]\n",
      "Classes scanned     : 119\n",
      "Exact matches       : 114\n",
      "Fuzzy matches       : 5\n",
      "Below threshold     : 0\n",
      "No candidates       : 0\n",
      "üßæ CSV saved to     : /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/imagenet_mappings_full.csv\n"
     ]
    }
   ],
   "source": [
    "map_info = map_folders_to_imagenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3dca757-abe2-480a-a406-b7c7eb9f1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 116 species...\n",
      "\n",
      "ankylosaurus: DONE (6 images)\n",
      "apatosaurus: DONE (2 images)\n",
      "archaeopteryx: DONE (5 images)\n",
      "ant: DONE (1656 images)\n",
      "armadillo: DONE (1282 images)\n",
      "bat: DONE (1304 images)\n",
      "bird: DONE (2126 images)\n",
      "anteater: DONE (1015 images)\n",
      "bison: DONE (1625 images)\n",
      "antelope: DONE (1282 images)\n",
      "beetle: DONE (1488 images)\n",
      "buffalo: DONE (1226 images)\n",
      "boar: DONE (1290 images)\n",
      "cardinal: DONE (1236 images)\n",
      "camel: DONE (1428 images)\n",
      "chameleon: DONE (1150 images)\n",
      "cat: DONE (1485 images)\n",
      "chipmunk: DONE (1255 images)\n",
      "chicken: DONE (1125 images)\n",
      "coelophysis: FAILED (download/404)\n",
      "cockroach: DONE (1157 images)\n",
      "cicada: DONE (1227 images)\n",
      "crab: DONE (1192 images)\n",
      "cricket: DONE (1308 images)\n",
      "crocodile: DONE (1322 images)\n",
      "crow: DONE (1435 images)\n",
      "butterfly: DONE (2115 images)\n",
      "deinonychus: FAILED (download/404)\n",
      "dimetrodon: DONE (48 images)\n",
      "diplodocus: FAILED (download/404)\n",
      "deer: DONE (1680 images)\n",
      "dolphin: DONE (930 images)\n",
      "cow: DONE (1186 images)\n",
      "crane: DONE (1355 images)\n",
      "dragonfly: DONE (2113 images)\n",
      "eel: DONE (953 images)\n",
      "elephant: DONE (1387 images)\n",
      "dog: DONE (1603 images)\n",
      "eagle: DONE (1481 images)\n",
      "fly: DONE (1320 images)\n",
      "fox: DONE (1217 images)\n",
      "duck: DONE (1642 images)\n",
      "fish: DONE (1307 images)\n",
      "frog: DONE (1222 images)\n",
      "giraffe: DONE (1256 images)\n",
      "goldfish: DONE (1172 images)\n",
      "grasshopper: DONE (1482 images)\n",
      "gorilla: DONE (1915 images)\n",
      "hawk: DONE (1826 images)\n",
      "hippo: DONE (1391 images)\n",
      "insects: DONE (1272 images)\n",
      "horse: DONE (1402 images)\n",
      "jellyfish: DONE (1635 images)\n",
      "kangaroo: DONE (1556 images)\n",
      "kingfisher: DONE (1265 images)\n",
      "hummingbird: DONE (1361 images)\n",
      "hermit crab: DONE (1430 images)\n",
      "leopard: DONE (1400 images)\n",
      "koala: DONE (2469 images)\n",
      "lizard: DONE (1202 images)\n",
      "locust: DONE (767 images)\n",
      "lobster: DONE (1206 images)\n",
      "mantis: DONE (1499 images)\n",
      "monkey: DONE (1595 images)\n",
      "octopus: FAILED (download/404)\n",
      "mouse: DONE (1252 images)\n",
      "orangutan: DONE (1859 images)\n",
      "ostrich: DONE (1393 images)\n",
      "ox: DONE (940 images)\n",
      "owl: DONE (1296 images)\n",
      "panda: DONE (1832 images)\n",
      "parrot: DONE (1149 images)\n",
      "lionfish: DONE (1513 images)\n",
      "peacock: DONE (2093 images)\n",
      "pelican: DONE (1246 images)\n",
      "pig: DONE (1463 images)\n",
      "platypus: DONE (1078 images)\n",
      "rabbit: DONE (1468 images)\n",
      "puffin: DONE (1414 images)\n",
      "raptor: FAILED (download/404)\n",
      "raccoon: DONE (1722 images)\n",
      "penguin: DONE (1281 images)\n",
      "ray: DONE (1364 images)\n",
      "rodent: DONE (2330 images)\n",
      "sauropods: DONE (1 images)\n",
      "rat: DONE (1415 images)\n",
      "scorpion: DONE (1197 images)\n",
      "seahorse: DONE (1272 images)\n",
      "lion: DONE (1795 images)\n",
      "seal: DONE (1832 images)\n",
      "shark: DONE (1219 images)\n",
      "sheep: DONE (1273 images)\n",
      "sea urchin: DONE (1186 images)\n",
      "segmented_creatures: DONE (510 images)\n",
      "slug: FAILED (download/404)\n",
      "rhinoceros: DONE (1496 images)\n",
      "shrimp: DONE (1236 images)\n",
      "snake: DONE (1289 images)\n",
      "spider: DONE (1249 images)\n",
      "skunk: DONE (1061 images)\n",
      "stegosaurus: FAILED (download/404)\n",
      "styracosaurus: FAILED (download/404)\n",
      "squirrel: DONE (1192 images)\n",
      "sparrow: DONE (1536 images)\n",
      "swan: DONE (1314 images)\n",
      "trex: FAILED (download/404)\n",
      "triceratops: FAILED (download/404)\n",
      "snail: DONE (1837 images)\n",
      "tiger: DONE (2086 images)\n",
      "turkey: DONE (1065 images)\n",
      "turtle: DONE (1209 images)\n",
      "wolf: DONE (1391 images)\n",
      "whale: DONE (1194 images)\n",
      "wasp: DONE (1210 images)\n",
      "tortoise: DONE (1221 images)\n",
      "zebra: DONE (1474 images)\n",
      "\n",
      "Summary ‚Üí DONE: 106  SKIP: 0  FAILED: 10\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tarfile, tempfile, time, csv, hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "\n",
    "# === CONFIG ===\n",
    "PROJECT   = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN\")\n",
    "MAP_CSV   = PROJECT / \"Data\" / \"dataset\" / \"imagenet_mappings_full.csv\"   # <- uses columns: folder_name, wnid\n",
    "OUT_DIR   = PROJECT / \"data\" / \"dataset\" / \"clean\"/ \"animals\"                                   # download target\n",
    "BASE_URL  = \"https://image-net.org/data/winter21_whole\"\n",
    "\n",
    "MAX_WORKERS = 4\n",
    "TIMEOUT     = 45\n",
    "RETRIES     = 3\n",
    "PROBE_HEAD  = True   # try a HEAD first to quickly skip 404s\n",
    "\n",
    "# === HELPERS ===\n",
    "def ensure(p: Path): \n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def has_files(p: Path) -> bool:\n",
    "    return p.exists() and any(p.iterdir())\n",
    "\n",
    "def _sha1_short(path: Path, chunk=1024*1024) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk)\n",
    "            if not b: break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()[:10]\n",
    "\n",
    "def _safe_extract_member(tf: tarfile.TarFile, member: tarfile.TarInfo, out_dir: Path):\n",
    "    # prevent path traversal\n",
    "    name = Path(member.name).name\n",
    "    if not name:\n",
    "        return None\n",
    "    dest = out_dir / name\n",
    "    # avoid overwriting\n",
    "    if dest.exists():\n",
    "        stem, suf = dest.stem, dest.suffix\n",
    "        dest = out_dir / f\"{stem}__dup{int(time.time())}{suf}\"\n",
    "    # extract file content manually to preserve safety\n",
    "    src = tf.extractfile(member)\n",
    "    if src is None:\n",
    "        return None\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(dest, \"wb\") as f:\n",
    "        f.write(src.read())\n",
    "    return dest\n",
    "\n",
    "def dl(url: str, dst: Path, session: requests.Session) -> bool:\n",
    "    for _ in range(RETRIES):\n",
    "        try:\n",
    "            if PROBE_HEAD:\n",
    "                rh = session.head(url, timeout=TIMEOUT, allow_redirects=True)\n",
    "                if rh.status_code == 404:\n",
    "                    return False\n",
    "            r = session.get(url, stream=True, timeout=TIMEOUT)\n",
    "            if r.status_code == 404:\n",
    "                return False\n",
    "            r.raise_for_status()\n",
    "            with open(dst, \"wb\") as f:\n",
    "                for chunk in r.iter_content(1024 * 256):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            return True\n",
    "        except requests.RequestException:\n",
    "            time.sleep(2)\n",
    "    return False\n",
    "\n",
    "def extract(tp: Path, out: Path) -> int:\n",
    "    n = 0\n",
    "    with tarfile.open(tp, \"r\") as tf:\n",
    "        for m in tf.getmembers():\n",
    "            if not m.isfile():\n",
    "                continue\n",
    "            if _safe_extract_member(tf, m, out) is not None:\n",
    "                n += 1\n",
    "    return n\n",
    "\n",
    "def load_mapping_from_csv(csv_path: Path):\n",
    "    \"\"\"\n",
    "    Read folder_name -> wnid from imagenet_mappings_full.csv\n",
    "    Returns dict {species_folder: wnid}, skipping empty wnids.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    with open(csv_path, newline=\"\") as fp:\n",
    "        r = csv.DictReader(fp)\n",
    "        for row in r:\n",
    "            sp = (row.get(\"folder_name\") or \"\").strip()\n",
    "            wn = (row.get(\"wnid\") or \"\").strip()\n",
    "            if sp:\n",
    "                mapping[sp] = wn\n",
    "    return mapping\n",
    "\n",
    "def process(species: str, wnid: str, session: requests.Session) -> str:\n",
    "    if not wnid:\n",
    "        return f\"{species}: SKIP (no wnid)\"\n",
    "    out = OUT_DIR / species\n",
    "    if has_files(out):\n",
    "        return f\"{species}: SKIP (exists)\"\n",
    "    ensure(out)\n",
    "    url = f\"{BASE_URL}/{wnid}.tar\"\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as td:\n",
    "            tp = Path(td) / f\"{wnid}.tar\"\n",
    "            ok = dl(url, tp, session)\n",
    "            if not ok:\n",
    "                return f\"{species}: FAILED (download/404)\"\n",
    "            try:\n",
    "                n = extract(tp, out)\n",
    "            except tarfile.ReadError:\n",
    "                return f\"{species}: FAILED (corrupt tar)\"\n",
    "    except Exception as e:\n",
    "        return f\"{species}: FAILED ({type(e).__name__})\"\n",
    "    return f\"{species}: DONE ({n} images)\"\n",
    "\n",
    "def run_from_csv():\n",
    "    ensure(OUT_DIR)\n",
    "    mapping = load_mapping_from_csv(MAP_CSV)\n",
    "    tasks = [(s, w) for s, w in mapping.items() if w]  # skip empty wnids\n",
    "    print(f\"Downloading {len(tasks)} species...\\n\")\n",
    "    results = []\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update({\"User-Agent\": \"origami-imagenet-downloader/1.0\"})\n",
    "        with ThreadPoolExecutor(max_workers=max(1, MAX_WORKERS)) as ex:\n",
    "            futs = {ex.submit(process, s, w, session): s for s, w in tasks}\n",
    "            for fut in as_completed(futs):\n",
    "                status = fut.result()\n",
    "                print(status)\n",
    "                results.append(status)\n",
    "    done   = sum(\"DONE\" in r for r in results)\n",
    "    skip   = sum(\"SKIP\" in r for r in results)\n",
    "    failed = sum(\"FAILED\" in r for r in results)\n",
    "    print(f\"\\nSummary ‚Üí DONE: {done}  SKIP: {skip}  FAILED: {failed}\")\n",
    "\n",
    "# === run ===\n",
    "run_from_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f875f11-97f1-4013-80a6-6b668c0a2e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Total folders: 116\n",
      "üñºÔ∏è Total images: 4822\n",
      "\n",
      "Folder-wise counts:\n",
      "  ankylosaurus             : 13\n",
      "  ant                      : 8\n",
      "  anteater                 : 4\n",
      "  antelope                 : 24\n",
      "  apatosaurus              : 2\n",
      "  archaeopteryx            : 6\n",
      "  armadillo                : 9\n",
      "  bat                      : 117\n",
      "  beetle                   : 185\n",
      "  bird                     : 50\n",
      "  bison                    : 17\n",
      "  boar                     : 7\n",
      "  buffalo                  : 6\n",
      "  butterfly                : 116\n",
      "  camel                    : 45\n",
      "  cardinal                 : 9\n",
      "  cat                      : 150\n",
      "  chameleon                : 6\n",
      "  chicken                  : 80\n",
      "  chipmunk                 : 7\n",
      "  cicada                   : 13\n",
      "  cockroach                : 12\n",
      "  coelophysis              : 2\n",
      "  cow                      : 114\n",
      "  crab                     : 95\n",
      "  crane                    : 31\n",
      "  cricket                  : 3\n",
      "  crocodile                : 31\n",
      "  crow                     : 6\n",
      "  deer                     : 67\n",
      "  deinonychus              : 2\n",
      "  dimetrodon               : 1\n",
      "  diplodocus               : 6\n",
      "  dog                      : 129\n",
      "  dolphin                  : 22\n",
      "  dragonfly                : 180\n",
      "  duck                     : 91\n",
      "  eagle                    : 11\n",
      "  eel                      : 2\n",
      "  elephant                 : 104\n",
      "  fish                     : 114\n",
      "  fly                      : 10\n",
      "  fox                      : 48\n",
      "  frog                     : 90\n",
      "  giraffe                  : 66\n",
      "  goldfish                 : 20\n",
      "  gorilla                  : 33\n",
      "  grasshopper              : 130\n",
      "  hawk                     : 4\n",
      "  hermit crab              : 7\n",
      "  hippo                    : 18\n",
      "  horse                    : 85\n",
      "  hummingbird              : 133\n",
      "  insects                  : 23\n",
      "  jellyfish                : 6\n",
      "  kangaroo                 : 37\n",
      "  kingfisher               : 7\n",
      "  koala                    : 8\n",
      "  leopard                  : 10\n",
      "  lion                     : 54\n",
      "  lionfish                 : 5\n",
      "  lizard                   : 24\n",
      "  lobster                  : 21\n",
      "  locust                   : 4\n",
      "  mantis                   : 15\n",
      "  monkey                   : 20\n",
      "  mouse                    : 115\n",
      "  octopus                  : 2\n",
      "  orangutan                : 1\n",
      "  ostrich                  : 4\n",
      "  owl                      : 47\n",
      "  ox                       : 3\n",
      "  panda                    : 86\n",
      "  parrot                   : 101\n",
      "  peacock                  : 50\n",
      "  pelican                  : 16\n",
      "  penguin                  : 45\n",
      "  pig                      : 36\n",
      "  platypus                 : 2\n",
      "  puffin                   : 5\n",
      "  rabbit                   : 94\n",
      "  raccoon                  : 10\n",
      "  raptor                   : 26\n",
      "  rat                      : 3\n",
      "  ray                      : 9\n",
      "  rhinoceros               : 120\n",
      "  rodent                   : 14\n",
      "  sauropods                : 16\n",
      "  scorpion                 : 203\n",
      "  sea urchin               : 1\n",
      "  seahorse                 : 8\n",
      "  seal                     : 4\n",
      "  segmented_creatures      : 3\n",
      "  shark                    : 33\n",
      "  sheep                    : 24\n",
      "  shrimp                   : 5\n",
      "  skunk                    : 13\n",
      "  slug                     : 3\n",
      "  snail                    : 71\n",
      "  snake                    : 10\n",
      "  sparrow                  : 20\n",
      "  spider                   : 19\n",
      "  squirrel                 : 62\n",
      "  stegosaurus              : 192\n",
      "  styracosaurus            : 15\n",
      "  swan                     : 28\n",
      "  tiger                    : 70\n",
      "  tortoise                 : 94\n",
      "  trex                     : 149\n",
      "  triceratops              : 28\n",
      "  turkey                   : 5\n",
      "  turtle                   : 32\n",
      "  wasp                     : 23\n",
      "  whale                    : 2\n",
      "  wolf                     : 79\n",
      "  zebra                    : 46\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CLEAN_DIR = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean/origami_images\")\n",
    "\n",
    "def count_images_in_dir(base: Path):\n",
    "    image_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\", \".webp\"}\n",
    "    folder_counts = {}\n",
    "    total_images = 0\n",
    "\n",
    "    for folder in sorted([p for p in base.iterdir() if p.is_dir()]):\n",
    "        count = sum(1 for f in folder.rglob(\"*\") if f.suffix.lower() in image_exts)\n",
    "        folder_counts[folder.name] = count\n",
    "        total_images += count\n",
    "\n",
    "    print(f\"\\nüìÇ Total folders: {len(folder_counts)}\")\n",
    "    print(f\"üñºÔ∏è Total images: {total_images}\\n\")\n",
    "    print(\"Folder-wise counts:\")\n",
    "    for name, cnt in folder_counts.items():\n",
    "        print(f\"  {name:25s}: {cnt}\")\n",
    "\n",
    "    return folder_counts, total_images\n",
    "\n",
    "folder_counts, total_images = count_images_in_dir(CLEAN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4001161-2399-436d-8993-f8050700ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 labels with 4397 origami images total.\n",
      "ankylosaurus              | origami=  13 | target= 260 | picked=   6\n",
      "ant                       | origami=   8 | target= 320 | picked= 320\n",
      "anteater                  | origami=   4 | target= 160 | picked= 160\n",
      "antelope                  | origami=  24 | target= 480 | picked= 480\n",
      "apatosaurus               | origami=   2 | target=  80 | picked=   2\n",
      "archaeopteryx             | origami=   6 | target= 240 | picked=   5\n",
      "armadillo                 | origami=   9 | target= 360 | picked= 360\n",
      "bat                       | origami= 117 | target=1170 | picked=1170\n",
      "beetle                    | origami= 185 | target=1500 | picked=1488\n",
      "bird                      | origami=  50 | target= 800 | picked= 800\n",
      "bison                     | origami=  17 | target= 340 | picked= 340\n",
      "boar                      | origami=   7 | target= 280 | picked= 280\n",
      "buffalo                   | origami=   6 | target= 240 | picked= 240\n",
      "butterfly                 | origami= 116 | target=1160 | picked=1160\n",
      "camel                     | origami=  45 | target= 800 | picked= 800\n",
      "cardinal                  | origami=   9 | target= 360 | picked= 360\n",
      "cat                       | origami= 150 | target=1500 | picked=1485\n",
      "chameleon                 | origami=   6 | target= 240 | picked= 240\n",
      "chicken                   | origami=  80 | target= 800 | picked= 800\n",
      "chipmunk                  | origami=   7 | target= 280 | picked= 280\n",
      "cicada                    | origami=  13 | target= 260 | picked= 260\n",
      "cockroach                 | origami=  12 | target= 240 | picked= 240\n",
      "cow                       | origami= 114 | target=1140 | picked=1140\n",
      "crab                      | origami=  95 | target= 950 | picked= 950\n",
      "crane                     | origami=  31 | target= 620 | picked= 620\n",
      "cricket                   | origami=   3 | target= 120 | picked= 120\n",
      "crocodile                 | origami=  31 | target= 620 | picked= 620\n",
      "crow                      | origami=   6 | target= 240 | picked= 240\n",
      "deer                      | origami=  67 | target= 670 | picked= 670\n",
      "dimetrodon                | origami=   1 | target=  40 | picked=  40\n",
      "dog                       | origami= 129 | target=1290 | picked=1290\n",
      "dolphin                   | origami=  22 | target= 440 | picked= 440\n",
      "dragonfly                 | origami= 180 | target=1500 | picked=1500\n",
      "duck                      | origami=  91 | target= 910 | picked= 910\n",
      "eagle                     | origami=  11 | target= 220 | picked= 220\n",
      "eel                       | origami=   2 | target=  80 | picked=  80\n",
      "elephant                  | origami= 104 | target=1040 | picked=1040\n",
      "fish                      | origami= 114 | target=1140 | picked=1140\n",
      "fly                       | origami=  10 | target= 400 | picked= 400\n",
      "fox                       | origami=  48 | target= 800 | picked= 800\n",
      "frog                      | origami=  90 | target= 900 | picked= 900\n",
      "giraffe                   | origami=  66 | target= 660 | picked= 660\n",
      "goldfish                  | origami=  20 | target= 400 | picked= 400\n",
      "gorilla                   | origami=  33 | target= 660 | picked= 660\n",
      "grasshopper               | origami= 130 | target=1300 | picked=1300\n",
      "hawk                      | origami=   4 | target= 160 | picked= 160\n",
      "hermit crab               | origami=   7 | target= 280 | picked= 280\n",
      "hippo                     | origami=  18 | target= 360 | picked= 360\n",
      "horse                     | origami=  85 | target= 850 | picked= 850\n",
      "hummingbird               | origami= 133 | target=1330 | picked=1330\n",
      "insects                   | origami=  23 | target= 460 | picked= 460\n",
      "jellyfish                 | origami=   6 | target= 240 | picked= 240\n",
      "kangaroo                  | origami=  37 | target= 740 | picked= 740\n",
      "kingfisher                | origami=   7 | target= 280 | picked= 280\n",
      "koala                     | origami=   8 | target= 320 | picked= 320\n",
      "leopard                   | origami=  10 | target= 400 | picked= 400\n",
      "lion                      | origami=  54 | target= 540 | picked= 540\n",
      "lionfish                  | origami=   5 | target= 200 | picked= 200\n",
      "lizard                    | origami=  24 | target= 480 | picked= 480\n",
      "lobster                   | origami=  21 | target= 420 | picked= 420\n",
      "locust                    | origami=   4 | target= 160 | picked= 160\n",
      "mantis                    | origami=  15 | target= 300 | picked= 300\n",
      "monkey                    | origami=  20 | target= 400 | picked= 400\n",
      "mouse                     | origami= 115 | target=1150 | picked=1150\n",
      "orangutan                 | origami=   1 | target=  40 | picked=  40\n",
      "ostrich                   | origami=   4 | target= 160 | picked= 160\n",
      "owl                       | origami=  47 | target= 800 | picked= 800\n",
      "ox                        | origami=   3 | target= 120 | picked= 120\n",
      "panda                     | origami=  86 | target= 860 | picked= 860\n",
      "parrot                    | origami= 101 | target=1010 | picked=1010\n",
      "peacock                   | origami=  50 | target= 800 | picked= 800\n",
      "pelican                   | origami=  16 | target= 320 | picked= 320\n",
      "penguin                   | origami=  45 | target= 800 | picked= 800\n",
      "pig                       | origami=  36 | target= 720 | picked= 720\n",
      "platypus                  | origami=   2 | target=  80 | picked=  80\n",
      "puffin                    | origami=   5 | target= 200 | picked= 200\n",
      "rabbit                    | origami=  94 | target= 940 | picked= 940\n",
      "raccoon                   | origami=  10 | target= 400 | picked= 400\n",
      "rat                       | origami=   3 | target= 120 | picked= 120\n",
      "ray                       | origami=   9 | target= 360 | picked= 360\n",
      "rhinoceros                | origami= 120 | target=1200 | picked=1200\n",
      "rodent                    | origami=  14 | target= 280 | picked= 280\n",
      "sauropods                 | origami=  16 | target= 320 | picked=   1\n",
      "scorpion                  | origami= 203 | target=1500 | picked=1197\n",
      "sea urchin                | origami=   1 | target=  40 | picked=  40\n",
      "seahorse                  | origami=   8 | target= 320 | picked= 320\n",
      "seal                      | origami=   4 | target= 160 | picked= 160\n",
      "segmented_creatures       | origami=   3 | target= 120 | picked= 120\n",
      "shark                     | origami=  33 | target= 660 | picked= 660\n",
      "sheep                     | origami=  24 | target= 480 | picked= 480\n",
      "shrimp                    | origami=   5 | target= 200 | picked= 200\n",
      "skunk                     | origami=  13 | target= 260 | picked= 260\n",
      "snail                     | origami=  71 | target= 710 | picked= 710\n",
      "snake                     | origami=  10 | target= 400 | picked= 400\n",
      "sparrow                   | origami=  20 | target= 400 | picked= 400\n",
      "spider                    | origami=  19 | target= 380 | picked= 380\n",
      "squirrel                  | origami=  62 | target= 620 | picked= 620\n",
      "swan                      | origami=  28 | target= 560 | picked= 560\n",
      "tiger                     | origami=  70 | target= 700 | picked= 700\n",
      "tortoise                  | origami=  94 | target= 940 | picked= 940\n",
      "turkey                    | origami=   5 | target= 200 | picked= 200\n",
      "turtle                    | origami=  32 | target= 640 | picked= 640\n",
      "wasp                      | origami=  23 | target= 460 | picked= 460\n",
      "whale                     | origami=   2 | target=  80 | picked=  80\n",
      "wolf                      | origami=  79 | target= 790 | picked= 790\n",
      "zebra                     | origami=  46 | target= 800 | picked= 800\n",
      "\n",
      "‚úÖ Done. Copied balanced animal images to: /Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean/animals_balanced\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simplified script:\n",
    "Takes counts from origami_images/ folders,\n",
    "computes how many animal images are needed for each label,\n",
    "and copies that many random samples from animals_src_dir/<label>/ into output_dir/<label>/\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "ORIGAMI_DIR = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean/origami_images\")       # path to origami folders\n",
    "ANIMALS_SRC_DIR = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean/animals\")      # path to real animal images\n",
    "OUTPUT_DIR = Path(\"/Users/antranakhasi/Desktop/Projects/Origami model using CycleGAN/Origami-Model-using-CycleGAN/Data/dataset/clean/animals_balanced\")      # where to save balanced data\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\"}  # allowed extensions\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "def iter_image_files(folder: Path):\n",
    "    \"\"\"Return list of image files in folder.\"\"\"\n",
    "    if not folder.exists():\n",
    "        return []\n",
    "    return [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in IMAGE_EXTS]\n",
    "\n",
    "\n",
    "def count_origami_by_label(root: Path):\n",
    "    \"\"\"Return list of (label, count) for each origami subfolder.\"\"\"\n",
    "    rows = []\n",
    "    for sub in sorted(root.iterdir()):\n",
    "        if sub.is_dir():\n",
    "            n = len(iter_image_files(sub))\n",
    "            rows.append((sub.name, n))\n",
    "    return rows\n",
    "\n",
    "\n",
    "def recommend_real_target(n: int) -> int:\n",
    "    \"\"\"Apply balancing rules.\"\"\"\n",
    "    if n <= 0:\n",
    "        target = 0\n",
    "    elif n <= 10:\n",
    "        target = min(n * 40, 400)\n",
    "    elif n <= 50:\n",
    "        target = min(n * 20, 800)\n",
    "    elif n <= 150:\n",
    "        target = min(n * 10, 1500)\n",
    "    else:\n",
    "        target = 1500\n",
    "    return int(round(target / 10.0) * 10)\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(42)\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    label_counts = count_origami_by_label(ORIGAMI_DIR)\n",
    "    if not label_counts:\n",
    "        print(f\"No labels found in {ORIGAMI_DIR}\")\n",
    "        return\n",
    "\n",
    "    total_origami = sum(c for _, c in label_counts)\n",
    "    print(f\"Found {len(label_counts)} labels with {total_origami} origami images total.\")\n",
    "\n",
    "    total_target = 0\n",
    "    for label, count in label_counts:\n",
    "        target = recommend_real_target(count)\n",
    "        total_target += target\n",
    "\n",
    "        src_folder = ANIMALS_SRC_DIR / label\n",
    "        dst_folder = OUTPUT_DIR / label\n",
    "        dst_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if not src_folder.exists():\n",
    "            print(f\"‚ö†Ô∏è Missing animal folder: {src_folder}\")\n",
    "            continue\n",
    "\n",
    "        files = iter_image_files(src_folder)\n",
    "        if not files:\n",
    "            print(f\"‚ö†Ô∏è No images in {src_folder}\")\n",
    "            continue\n",
    "\n",
    "        chosen = random.sample(files, min(target, len(files)))\n",
    "        for f in chosen:\n",
    "            shutil.copy2(f, dst_folder / f.name)\n",
    "\n",
    "        print(f\"{label:25s} | origami={count:4d} | target={target:4d} | picked={len(chosen):4d}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Done. Copied balanced animal images to: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9b2ae-b6da-4b13-ae38-81377025f29e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
